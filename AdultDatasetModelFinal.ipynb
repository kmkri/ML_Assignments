{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7320245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\shwet\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\shwet\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\shwet\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.1.4)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shwet\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shwet\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shwet\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install imbalanced-learn\n",
    "#Installing ucimlrepo package\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e54f1187-3b0f-411b-abf0-87f28bb73405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy.stats as stats  # Import the stats module for ANOVA\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a79b87ce-1134-45e2-833a-212c6300ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "The following datasets are available:\n",
      "-------------------------------------\n",
      "Dataset Name                                                                            ID    \n",
      "------------                                                                            --    \n",
      "Abalone                                                                                 1     \n",
      "Adult                                                                                   2     \n",
      "Annealing                                                                               3     \n",
      "Audiology (Standardized)                                                                8     \n",
      "Auto MPG                                                                                9     \n",
      "Automobile                                                                              10    \n",
      "Balance Scale                                                                           12    \n",
      "Balloons                                                                                13    \n",
      "Breast Cancer                                                                           14    \n",
      "Breast Cancer Wisconsin (Original)                                                      15    \n",
      "Breast Cancer Wisconsin (Prognostic)                                                    16    \n",
      "Breast Cancer Wisconsin (Diagnostic)                                                    17    \n",
      "Pittsburgh Bridges                                                                      18    \n",
      "Car Evaluation                                                                          19    \n",
      "Census Income                                                                           20    \n",
      "Chess (King-Rook vs. King-Pawn)                                                         22    \n",
      "Chess (King-Rook vs. King)                                                              23    \n",
      "Connect-4                                                                               26    \n",
      "Credit Approval                                                                         27    \n",
      "Japanese Credit Screening                                                               28    \n",
      "Computer Hardware                                                                       29    \n",
      "Contraceptive Method Choice                                                             30    \n",
      "Covertype                                                                               31    \n",
      "Cylinder Bands                                                                          32    \n",
      "Dermatology                                                                             33    \n",
      "Echocardiogram                                                                          38    \n",
      "Ecoli                                                                                   39    \n",
      "Flags                                                                                   40    \n",
      "Glass Identification                                                                    42    \n",
      "Haberman's Survival                                                                     43    \n",
      "Hayes-Roth                                                                              44    \n",
      "Heart Disease                                                                           45    \n",
      "Hepatitis                                                                               46    \n",
      "Horse Colic                                                                             47    \n",
      "Image Segmentation                                                                      50    \n",
      "Ionosphere                                                                              52    \n",
      "Iris                                                                                    53    \n",
      "ISOLET                                                                                  54    \n",
      "Lenses                                                                                  58    \n",
      "Letter Recognition                                                                      59    \n",
      "Liver Disorders                                                                         60    \n",
      "Lung Cancer                                                                             62    \n",
      "Lymphography                                                                            63    \n",
      "Molecular Biology (Splice-junction Gene Sequences)                                      69    \n",
      "MONK's Problems                                                                         70    \n",
      "Mushroom                                                                                73    \n",
      "Musk (Version 1)                                                                        74    \n",
      "Musk (Version 2)                                                                        75    \n",
      "Nursery                                                                                 76    \n",
      "Page Blocks Classification                                                              78    \n",
      "Optical Recognition of Handwritten Digits                                               80    \n",
      "Pen-Based Recognition of Handwritten Digits                                             81    \n",
      "Post-Operative Patient                                                                  82    \n",
      "Primary Tumor                                                                           83    \n",
      "Servo                                                                                   87    \n",
      "Shuttle Landing Control                                                                 88    \n",
      "Solar Flare                                                                             89    \n",
      "Soybean (Large)                                                                         90    \n",
      "Soybean (Small)                                                                         91    \n",
      "Challenger USA Space Shuttle O-Ring                                                     92    \n",
      "Spambase                                                                                94    \n",
      "SPECT Heart                                                                             95    \n",
      "SPECTF Heart                                                                            96    \n",
      "Tic-Tac-Toe Endgame                                                                     101   \n",
      "Congressional Voting Records                                                            105   \n",
      "Waveform Database Generator (Version 1)                                                 107   \n",
      "Wine                                                                                    109   \n",
      "Yeast                                                                                   110   \n",
      "Zoo                                                                                     111   \n",
      "US Census Data (1990)                                                                   116   \n",
      "Census-Income (KDD)                                                                     117   \n",
      "El Nino                                                                                 122   \n",
      "Statlog (Australian Credit Approval)                                                    143   \n",
      "Statlog (German Credit Data)                                                            144   \n",
      "Statlog (Heart)                                                                         145   \n",
      "Statlog (Landsat Satellite)                                                             146   \n",
      "Statlog (Image Segmentation)                                                            147   \n",
      "Statlog (Shuttle)                                                                       148   \n",
      "Statlog (Vehicle Silhouettes)                                                           149   \n",
      "Connectionist Bench (Sonar, Mines vs. Rocks)                                            151   \n",
      "Cloud                                                                                   155   \n",
      "Poker Hand                                                                              158   \n",
      "MAGIC Gamma Telescope                                                                   159   \n",
      "Mammographic Mass                                                                       161   \n",
      "Forest Fires                                                                            162   \n",
      "Concrete Compressive Strength                                                           165   \n",
      "Ozone Level Detection                                                                   172   \n",
      "Parkinsons                                                                              174   \n",
      "Blood Transfusion Service Center                                                        176   \n",
      "Communities and Crime                                                                   183   \n",
      "Acute Inflammations                                                                     184   \n",
      "Wine Quality                                                                            186   \n",
      "Parkinsons Telemonitoring                                                               189   \n",
      "Cardiotocography                                                                        193   \n",
      "Steel Plates Faults                                                                     198   \n",
      "Communities and Crime Unnormalized                                                      211   \n",
      "Vertebral Column                                                                        212   \n",
      "Bank Marketing                                                                          222   \n",
      "ILPD (Indian Liver Patient Dataset)                                                     225   \n",
      "Skin Segmentation                                                                       229   \n",
      "Individual Household Electric Power Consumption                                         235   \n",
      "Energy Efficiency                                                                       242   \n",
      "Fertility                                                                               244   \n",
      "ISTANBUL STOCK EXCHANGE                                                                 247   \n",
      "User Knowledge Modeling                                                                 257   \n",
      "EEG Eye State                                                                           264   \n",
      "Banknote Authentication                                                                 267   \n",
      "Gas Sensor Array Drift at Different Concentrations                                      270   \n",
      "Bike Sharing                                                                            275   \n",
      "Thoracic Surgery Data                                                                   277   \n",
      "Airfoil Self-Noise                                                                      291   \n",
      "Wholesale customers                                                                     292   \n",
      "Combined Cycle Power Plant                                                              294   \n",
      "Diabetes 130-US Hospitals for Years 1999-2008                                           296   \n",
      "Tennis Major Tournament Match Statistics                                                300   \n",
      "Dow Jones Index                                                                         312   \n",
      "Student Performance                                                                     320   \n",
      "Phishing Websites                                                                       327   \n",
      "Diabetic Retinopathy Debrecen                                                           329   \n",
      "Online News Popularity                                                                  332   \n",
      "Chronic Kidney Disease                                                                  336   \n",
      "Mice Protein Expression                                                                 342   \n",
      "Default of Credit Card Clients                                                          350   \n",
      "Online Retail                                                                           352   \n",
      "Occupancy Detection                                                                     357   \n",
      "Air Quality                                                                             360   \n",
      "Polish Companies Bankruptcy                                                             365   \n",
      "Dota2 Games Results                                                                     367   \n",
      "Facebook Metrics                                                                        368   \n",
      "HTRU2                                                                                   372   \n",
      "Drug Consumption (Quantified)                                                           373   \n",
      "Appliances Energy Prediction                                                            374   \n",
      "Website Phishing                                                                        379   \n",
      "YouTube Spam Collection                                                                 380   \n",
      "Beijing PM2.5                                                                           381   \n",
      "Cervical Cancer (Risk Factors)                                                          383   \n",
      "Stock Portfolio Performance                                                             390   \n",
      "Sales Transactions Weekly                                                               396   \n",
      "Daily Demand Forecasting Orders                                                         409   \n",
      "Autistic Spectrum Disorder Screening Data for Children                                  419   \n",
      "Autism Screening Adult                                                                  426   \n",
      "Absenteeism at work                                                                     445   \n",
      "Breast Cancer Coimbra                                                                   451   \n",
      "Drug Reviews (Druglib.com)                                                              461   \n",
      "Drug Reviews (Drugs.com)                                                                462   \n",
      "Superconductivty Data                                                                   464   \n",
      "Student Academics Performance                                                           467   \n",
      "Online Shoppers Purchasing Intention Dataset                                            468   \n",
      "Electrical Grid Stability Simulated Data                                                471   \n",
      "Real Estate Valuation                                                                   477   \n",
      "Travel Reviews                                                                          484   \n",
      "Travel Review Ratings                                                                   485   \n",
      "Facebook Live Sellers in Thailand                                                       488   \n",
      "Metro Interstate Traffic Volume                                                         492   \n",
      "Hepatitis C Virus (HCV) for Egyptian patients                                           503   \n",
      "Heart Failure Clinical Records                                                          519   \n",
      "Early Stage Diabetes Risk Prediction                                                    529   \n",
      "Pedestrians in Traffic                                                                  536   \n",
      "Cervical Cancer Behavior Risk                                                           537   \n",
      "Estimation of Obesity Levels Based On Eating Habits and Physical Condition              544   \n",
      "Rice (Cammeo and Osmancik)                                                              545   \n",
      "Algerian Forest Fires                                                                   547   \n",
      "Gas Turbine CO and NOx Emission Data Set                                                551   \n",
      "Apartment for Rent Classified                                                           555   \n",
      "Seoul Bike Sharing Demand                                                               560   \n",
      "Iranian Churn                                                                           563   \n",
      "Bone marrow transplant: children                                                        565   \n",
      "COVID-19 Surveillance                                                                   567   \n",
      "HCV data                                                                                571   \n",
      "Taiwanese Bankruptcy Prediction                                                         572   \n",
      "Myocardial infarction complications                                                     579   \n",
      "Student Performance on an Entrance Examination                                          582   \n",
      "Gender by Name                                                                          591   \n",
      "Productivity Prediction of Garment Employees                                            597   \n",
      "AI4I 2020 Predictive Maintenance Dataset                                                601   \n",
      "Dry Bean                                                                                602   \n",
      "In-Vehicle Coupon Recommendation                                                        603   \n",
      "Predict Students' Dropout and Academic Success                                          697   \n",
      "Auction Verification                                                                    713   \n",
      "NATICUSdroid (Android Permissions)                                                      722   \n",
      "Toxicity                                                                                728   \n",
      "DARWIN                                                                                  732   \n",
      "Accelerometer Gyro Mobile Phone                                                         755   \n",
      "Glioma Grading Clinical and Mutation Features                                           759   \n",
      "Multivariate Gait Data                                                                  760   \n",
      "Land Mines                                                                              763   \n",
      "Single Elder Home Monitoring: Gas and Position                                          799   \n",
      "Sepsis Survival Minimal Clinical Records                                                827   \n",
      "Secondary Mushroom                                                                      848   \n",
      "Power Consumption of Tetouan City                                                       849   \n",
      "Raisin                                                                                  850   \n",
      "Steel Industry Energy Consumption                                                       851   \n",
      "Higher Education Students Performance Evaluation                                        856   \n",
      "Risk Factor Prediction of Chronic Kidney Disease                                        857   \n",
      "Maternal Health Risk                                                                    863   \n",
      "Room Occupancy Estimation                                                               864   \n",
      "Cirrhosis Patient Survival Prediction                                                   878   \n",
      "SUPPORT2                                                                                880   \n",
      "National Health and Nutrition Health Survey 2013-2014 (NHANES) Age Prediction Subset    887   \n",
      "AIDS Clinical Trials Group Study 175                                                    890   \n",
      "CDC Diabetes Health Indicators                                                          891   \n",
      "Recipe Reviews and User Feedback                                                        911   \n",
      "Forty Soybean Cultivars from Subsequent Harvests                                        913   \n",
      "Differentiated Thyroid Cancer Recurrence                                                915   \n",
      "Infrared Thermography Temperature                                                       925   \n",
      "National Poll on Healthy Aging (NPHA)                                                   936   \n",
      "Regensburg Pediatric Appendicitis                                                       938   \n",
      "RT-IoT2022                                                                              942   \n",
      "PhiUSIIL Phishing URL (Website)                                                         967   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fetching UCI repositories \n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "#List of UCI repositories with ID\n",
    "list_available_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d31a206-b8b0-4374-91a7-dfbbaef81852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States   <=50K  \n",
       "1      United-States   <=50K  \n",
       "2      United-States   <=50K  \n",
       "3      United-States   <=50K  \n",
       "4               Cuba   <=50K  \n",
       "...              ...     ...  \n",
       "48837  United-States  <=50K.  \n",
       "48838  United-States  <=50K.  \n",
       "48839  United-States  <=50K.  \n",
       "48840  United-States  <=50K.  \n",
       "48841  United-States   >50K.  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch dataset and create dataframe\n",
    "adult = fetch_ucirepo(id=2) \n",
    "adultDataFrame = adult.data.original\n",
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9287ab4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       "Private             33906\n",
       "Self-emp-not-inc     3862\n",
       "Local-gov            3136\n",
       "State-gov            1981\n",
       "?                    1836\n",
       "Self-emp-inc         1695\n",
       "Federal-gov          1432\n",
       "Without-pay            21\n",
       "Never-worked           10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldataset = adultDataFrame\n",
    "originaldataset['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39fa66b2-ecc9-433b-bcc8-2327de7d8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adultDataFrame1.replace('?', np.nan, inplace=True)\n",
    "# # Clean values in income column\n",
    "# adultDataFrame1['income'].replace('<=50K.', '<=50K',inplace = True)\n",
    "# adultDataFrame1['income'].replace('>50K.', '>50K',inplace = True)\n",
    "\n",
    "# print(\"Duplicate Rows:\\n\", adultDataFrame1.duplicated().sum())\n",
    "# duplicates  = adultDataFrame1[adultDataFrame1.duplicated()]\n",
    "# duplicates\n",
    "# duplicates[duplicates['fnlwgt']== 308144]\n",
    "# #Check and drop duplicates\n",
    "# adult_cleanedData = adultDataFrame1.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6f5b2ff-36ca-474a-a8fd-7e683d5ec043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      " 29\n",
      "Blank Rows (All NaN values): 0\n",
      "Duplicate Rows:\n",
      " 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country income  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3      United-States  <=50K  \n",
       "4               Cuba  <=50K  \n",
       "...              ...    ...  \n",
       "48837  United-States  <=50K  \n",
       "48838  United-States  <=50K  \n",
       "48839  United-States  <=50K  \n",
       "48840  United-States  <=50K  \n",
       "48841  United-States   >50K  \n",
       "\n",
       "[48790 rows x 15 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Data Cleaning\n",
    "print(\"Duplicate Rows:\\n\", adultDataFrame.duplicated().sum())\n",
    "# Identify rows where all values are NaN\n",
    "# Identify rows where all values are NaN\n",
    "blank_rows = adultDataFrame.isnull().all(axis=1)\n",
    "\n",
    "# Print the count of blank rows\n",
    "print(\"Blank Rows (All NaN values):\", blank_rows.sum())\n",
    "# Handling missing values ('?' is treated as missing in this dataset)\n",
    "adultDataFrame.replace('?', np.nan, inplace=True)\n",
    "\n",
    "#Check and drop duplicates\n",
    "# adult_cleanedData = adultDataFrame1.drop_duplicates(inplace=False)\n",
    "\n",
    " \n",
    "\n",
    "# Clean values in income column\n",
    "adultDataFrame['income'].replace('<=50K.', '<=50K',inplace = True)\n",
    "adultDataFrame['income'].replace('>50K.', '>50K',inplace = True)\n",
    "#adult_cleanedData\n",
    "adultDataFrame['income'].value_counts()\n",
    "\n",
    "print(\"Duplicate Rows:\\n\", adultDataFrame.duplicated().sum())\n",
    "duplicates  = adultDataFrame[adultDataFrame.duplicated()]\n",
    "#duplicates\n",
    "# #Check and drop duplicates\n",
    "#adult_cleanedData = adultDataFrame.drop_duplicates(inplace=False)\n",
    "adultDataFrame.drop_duplicates(inplace=True)\n",
    "\n",
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "748b920a-cc18-405d-a206-5469229db3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adultDataFrame['education_new'] = np.where(np.isin(adultDataFrame.education,['Preschool','1st-4th','5th-6th']),'Elementary',\n",
    "#                            np.where(np.isin(adultDataFrame.education,['7th-8th']),'Middle-School',\n",
    "#                            np.where(np.isin(adultDataFrame.education,['9th','10th','11th','12th']),'High-School',adultDataFrame.education)))\n",
    "# adultDataFrame[['education_new','education']].value_counts()\n",
    "\n",
    "adultDataFrame['education_new'] = np.where(np.isin(adultDataFrame.education,['Preschool','1st-4th','5th-6th','7th-8th','9th','10th','11th','12th']),\n",
    "                                    'Not HS-grad',adultDataFrame.education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8bd6c7e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>education_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \\\n",
       "0          2174             0              40  United-States  <=50K   \n",
       "1             0             0              13  United-States  <=50K   \n",
       "2             0             0              40  United-States  <=50K   \n",
       "3             0             0              40  United-States  <=50K   \n",
       "4             0             0              40           Cuba  <=50K   \n",
       "\n",
       "  education_new  \n",
       "0     Bachelors  \n",
       "1     Bachelors  \n",
       "2       HS-grad  \n",
       "3   Not HS-grad  \n",
       "4     Bachelors  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "adc34036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age         workclass  fnlwgt  education  education-num  \\\n",
      "0       39         State-gov   77516  Bachelors             13   \n",
      "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2       38           Private  215646    HS-grad              9   \n",
      "3       53           Private  234721       11th              7   \n",
      "4       28           Private  338409  Bachelors             13   \n",
      "...    ...               ...     ...        ...            ...   \n",
      "48837   39           Private  215419  Bachelors             13   \n",
      "48838   64               NaN  321403    HS-grad              9   \n",
      "48839   38           Private  374983  Bachelors             13   \n",
      "48840   44           Private   83891  Bachelors             13   \n",
      "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
      "\n",
      "           marital-status         occupation    relationship  \\\n",
      "0           Never-married       Adm-clerical   Not-in-family   \n",
      "1      Married-civ-spouse    Exec-managerial         Husband   \n",
      "2                Divorced  Handlers-cleaners   Not-in-family   \n",
      "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
      "4      Married-civ-spouse     Prof-specialty            Wife   \n",
      "...                   ...                ...             ...   \n",
      "48837            Divorced     Prof-specialty   Not-in-family   \n",
      "48838             Widowed                NaN  Other-relative   \n",
      "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
      "48840            Divorced       Adm-clerical       Own-child   \n",
      "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
      "\n",
      "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "0                   White    Male          2174             0              40   \n",
      "1                   White    Male             0             0              13   \n",
      "2                   White    Male             0             0              40   \n",
      "3                   Black    Male             0             0              40   \n",
      "4                   Black  Female             0             0              40   \n",
      "...                   ...     ...           ...           ...             ...   \n",
      "48837               White  Female             0             0              36   \n",
      "48838               Black    Male             0             0              40   \n",
      "48839               White    Male             0             0              50   \n",
      "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
      "48841               White    Male             0             0              60   \n",
      "\n",
      "      native-country income education_new    age_group  \n",
      "0      United-States  <=50K     Bachelors        Adult  \n",
      "1      United-States  <=50K     Bachelors        Adult  \n",
      "2      United-States  <=50K       HS-grad        Adult  \n",
      "3      United-States  <=50K   Not HS-grad        Adult  \n",
      "4               Cuba  <=50K     Bachelors  Young Adult  \n",
      "...              ...    ...           ...          ...  \n",
      "48837  United-States  <=50K     Bachelors        Adult  \n",
      "48838  United-States  <=50K       HS-grad       Senior  \n",
      "48839  United-States  <=50K     Bachelors        Adult  \n",
      "48840  United-States  <=50K     Bachelors        Adult  \n",
      "48841  United-States   >50K     Bachelors        Adult  \n",
      "\n",
      "[48790 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define bins and labels for age categories\n",
    "bins = [0, 13, 20, 35, 61, 100]  # Age intervals\n",
    "labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']  # Corresponding labels\n",
    "\n",
    "# Use pd.cut to categorize the age into groups\n",
    "adultDataFrame['age_group'] = pd.cut(adultDataFrame['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(adultDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0cb5adac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group\n",
       "Adult          24212\n",
       "Young Adult    18473\n",
       "Senior          3605\n",
       "Teen            2500\n",
       "Child              0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fccaa60f-2514-40b1-9332-7ddb4695f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the column which are not needed\n",
    "adultDataFrame.drop(columns=['fnlwgt','education','education-num','age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "998e2900-f500-4aef-ba5c-a6ca01342ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>education_new</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              workclass      marital-status         occupation  \\\n",
       "0             State-gov       Never-married       Adm-clerical   \n",
       "1      Self-emp-not-inc  Married-civ-spouse    Exec-managerial   \n",
       "2               Private            Divorced  Handlers-cleaners   \n",
       "3               Private  Married-civ-spouse  Handlers-cleaners   \n",
       "4               Private  Married-civ-spouse     Prof-specialty   \n",
       "...                 ...                 ...                ...   \n",
       "48837           Private            Divorced     Prof-specialty   \n",
       "48838               NaN             Widowed                NaN   \n",
       "48839           Private  Married-civ-spouse     Prof-specialty   \n",
       "48840           Private            Divorced       Adm-clerical   \n",
       "48841      Self-emp-inc  Married-civ-spouse    Exec-managerial   \n",
       "\n",
       "         relationship                race     sex  capital-gain  capital-loss  \\\n",
       "0       Not-in-family               White    Male          2174             0   \n",
       "1             Husband               White    Male             0             0   \n",
       "2       Not-in-family               White    Male             0             0   \n",
       "3             Husband               Black    Male             0             0   \n",
       "4                Wife               Black  Female             0             0   \n",
       "...               ...                 ...     ...           ...           ...   \n",
       "48837   Not-in-family               White  Female             0             0   \n",
       "48838  Other-relative               Black    Male             0             0   \n",
       "48839         Husband               White    Male             0             0   \n",
       "48840       Own-child  Asian-Pac-Islander    Male          5455             0   \n",
       "48841         Husband               White    Male             0             0   \n",
       "\n",
       "       hours-per-week native-country income education_new    age_group  \n",
       "0                  40  United-States  <=50K     Bachelors        Adult  \n",
       "1                  13  United-States  <=50K     Bachelors        Adult  \n",
       "2                  40  United-States  <=50K       HS-grad        Adult  \n",
       "3                  40  United-States  <=50K   Not HS-grad        Adult  \n",
       "4                  40           Cuba  <=50K     Bachelors  Young Adult  \n",
       "...               ...            ...    ...           ...          ...  \n",
       "48837              36  United-States  <=50K     Bachelors        Adult  \n",
       "48838              40  United-States  <=50K       HS-grad       Senior  \n",
       "48839              50  United-States  <=50K     Bachelors        Adult  \n",
       "48840              40  United-States  <=50K     Bachelors        Adult  \n",
       "48841              60  United-States   >50K     Bachelors        Adult  \n",
       "\n",
       "[48790 rows x 13 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87e1ae9e-dd0b-4e00-bdc3-dde46fe8932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adultDataFrame.loc[adultDataFrame['workclass'] == 'Never-worked', 'hours-per-week'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b07e074-84ef-4643-a492-8376a4d62ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>education_new</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5361</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10845</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14772</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23232</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32304</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32314</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41346</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44168</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Young Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46459</th>\n",
       "      <td>Never-worked</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Not HS-grad</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          workclass         marital-status occupation    relationship   race  \\\n",
       "5361   Never-worked          Never-married        NaN       Own-child  White   \n",
       "10845  Never-worked               Divorced        NaN   Not-in-family  White   \n",
       "14772  Never-worked          Never-married        NaN       Own-child  White   \n",
       "20337  Never-worked          Never-married        NaN       Own-child  White   \n",
       "23232  Never-worked          Never-married        NaN       Own-child  Black   \n",
       "32304  Never-worked     Married-civ-spouse        NaN            Wife  Black   \n",
       "32314  Never-worked          Never-married        NaN       Own-child  White   \n",
       "41346  Never-worked          Never-married        NaN       Own-child  Black   \n",
       "44168  Never-worked  Married-spouse-absent        NaN  Other-relative  White   \n",
       "46459  Never-worked          Never-married        NaN       Own-child  White   \n",
       "\n",
       "          sex  capital-gain  capital-loss  hours-per-week native-country  \\\n",
       "5361     Male             0             0               0  United-States   \n",
       "10845    Male             0             0               0  United-States   \n",
       "14772    Male             0             0               0  United-States   \n",
       "20337  Female             0             0               0  United-States   \n",
       "23232    Male             0             0               0  United-States   \n",
       "32304  Female             0             0               0  United-States   \n",
       "32314    Male             0             0               0  United-States   \n",
       "41346  Female             0             0               0  United-States   \n",
       "44168    Male             0             0               0  United-States   \n",
       "46459    Male             0             0               0  United-States   \n",
       "\n",
       "      income education_new    age_group  \n",
       "5361   <=50K   Not HS-grad         Teen  \n",
       "10845  <=50K   Not HS-grad  Young Adult  \n",
       "14772  <=50K   Not HS-grad         Teen  \n",
       "20337  <=50K   Not HS-grad         Teen  \n",
       "23232  <=50K  Some-college  Young Adult  \n",
       "32304  <=50K       HS-grad  Young Adult  \n",
       "32314  <=50K  Some-college         Teen  \n",
       "41346  <=50K   Not HS-grad         Teen  \n",
       "44168  <=50K       HS-grad  Young Adult  \n",
       "46459  <=50K   Not HS-grad         Teen  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame.loc[adultDataFrame['workclass'] == 'Never-worked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bb227344-cb81-4f53-a9d3-c485a12fb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 13 16 45 50 80 30 35 60 20 52 44 15 25 38 43 55 48 58 32 70  2 22 56\n",
      " 41 28 36 24 46 42 12 65  1 10 34 75 33 54  8  6 64 19 18 72  5  9 47 37\n",
      " 21 26 14  4 59  7 53 39 62 57 78 66 11 49  3 17 68 27 31 51 77  0 63 23\n",
      " 73 29 67 76 61 74 79 69]\n"
     ]
    }
   ],
   "source": [
    "# Cap 'hours-per-week' at 80adultDataFrame\n",
    "adultDataFrame['hours-per-week'] = adultDataFrame['hours-per-week'].apply(lambda x: 80 if x > 80 else x)\n",
    "\n",
    "# Verify the changes\n",
    "print(adultDataFrame['hours-per-week'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd1025",
   "metadata": {},
   "source": [
    "## **Encoding** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc997bc3-3314-4755-9493-dc2afbd48644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #encoding values \n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encode_columns = ['age_group','workclass','occupation','marital-status','education_new','relationship','race','sex','native-country','income']\n",
    "\n",
    "# for column in encode_columns:\n",
    "#      adultDataFrame[column+'_enc'] = LabelEncoder().fit_transform(adultDataFrame[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d271c194-b6a5-496b-bc74-e034818da563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2795"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['workclass'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e94b38a2-c030-46ec-a2df-b748972f2f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2805"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['occupation'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53c696",
   "metadata": {},
   "source": [
    "## **Imputing the missing values** ##\n",
    "**(because duirng oversampling SMOTE require a complete dataset with no missing values to create synthetic samples accurately)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89c4fe",
   "metadata": {},
   "source": [
    "**Imputing the missing values for workclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8a5e434-28da-4972-a8b6-70af5cafbc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values to impute for workclass_enc\n",
      "No missing values to impute for occupation_enc\n",
      "workclass_enc\n",
      "3    33860\n",
      "5     3861\n",
      "1     3136\n",
      "8     2795\n",
      "6     1981\n",
      "4     1694\n",
      "0     1432\n",
      "7       21\n",
      "2       10\n",
      "Name: count, dtype: int64\n",
      "occupation_enc\n",
      "9     6165\n",
      "2     6102\n",
      "3     6082\n",
      "0     5606\n",
      "11    5501\n",
      "7     4919\n",
      "6     3017\n",
      "14    2805\n",
      "13    2355\n",
      "5     2071\n",
      "4     1485\n",
      "12    1445\n",
      "10     982\n",
      "8      240\n",
      "1       15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of columns to encode\n",
    "encode_columns = ['age_group', 'workclass', 'occupation', 'marital-status', 'education_new',\n",
    "                  'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "\n",
    "# Apply LabelEncoder to the columns that need to be encoded\n",
    "label_encoders = {}\n",
    "for column in encode_columns:\n",
    "    le = LabelEncoder()\n",
    "    adultDataFrame[column + '_enc'] = le.fit_transform(adultDataFrame[column])\n",
    "    label_encoders[column] = le  # Save the encoder for potential reverse mapping if needed\n",
    "\n",
    "# Drop the original non-encoded columns\n",
    "adultDataFrame_encoded = adultDataFrame.drop(columns=encode_columns)\n",
    "\n",
    "# Function to impute missing values for a specified column using RandomForestClassifier\n",
    "\n",
    "\n",
    "def impute_column(df, target_col, random_state=42):\n",
    "    # Separate rows with and without missing values\n",
    "    df_missing = df[df[target_col].isnull()]\n",
    "    df_not_missing = df[df[target_col].notnull()]\n",
    "\n",
    "    # Ensure there are non-empty samples for imputation\n",
    "    if df_missing.empty:\n",
    "        print(f\"No missing values to impute for {target_col}\")\n",
    "        return df\n",
    "\n",
    "    # Define features and target, excluding the target column itself\n",
    "    X = df_not_missing.drop(columns=[target_col])  # Features (exclude the target column)\n",
    "    y = df_not_missing[target_col]  # Target variable (the column to impute)\n",
    "\n",
    "    # Ensure there are non-empty samples for training\n",
    "    if X.empty or y.empty:\n",
    "        raise ValueError(f\"No valid training samples for {target_col} imputation.\")\n",
    "\n",
    "    # Split the non-missing data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    # Initialize and train the Random Forest Classifier\n",
    "    rf = RandomForestClassifier(random_state=random_state)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict missing values\n",
    "    X_missing = df_missing.drop(columns=[target_col])  # Features for rows with missing values\n",
    "\n",
    "    if X_missing.empty:\n",
    "        raise ValueError(f\"No valid samples with missing values for {target_col} imputation.\")\n",
    "\n",
    "    df_missing[target_col] = rf.predict(X_missing)\n",
    "\n",
    "    # Combine the imputed and non-missing data back together\n",
    "    df_imputed = pd.concat([df_not_missing, df_missing])\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "# Apply the imputation for both 'workclass_enc' and 'occupation_enc'\n",
    "adultDataFrame_encoded = impute_column(adultDataFrame_encoded, 'workclass_enc')\n",
    "adultDataFrame_encoded = impute_column(adultDataFrame_encoded, 'occupation_enc')\n",
    "\n",
    "# Display the imputed DataFrame and the value counts for verification\n",
    "print(adultDataFrame_encoded['workclass_enc'].value_counts())\n",
    "print(adultDataFrame_encoded['occupation_enc'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d1801d4e-1754-48a3-8724-7c182a6af98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>age_group_enc</th>\n",
       "      <th>workclass_enc</th>\n",
       "      <th>occupation_enc</th>\n",
       "      <th>marital-status_enc</th>\n",
       "      <th>education_new_enc</th>\n",
       "      <th>relationship_enc</th>\n",
       "      <th>race_enc</th>\n",
       "      <th>sex_enc</th>\n",
       "      <th>native-country_enc</th>\n",
       "      <th>income_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       capital-gain  capital-loss  hours-per-week  age_group_enc  \\\n",
       "0              2174             0              40              0   \n",
       "1                 0             0              13              0   \n",
       "2                 0             0              40              0   \n",
       "3                 0             0              40              0   \n",
       "4                 0             0              40              3   \n",
       "...             ...           ...             ...            ...   \n",
       "48837             0             0              36              0   \n",
       "48838             0             0              40              1   \n",
       "48839             0             0              50              0   \n",
       "48840          5455             0              40              0   \n",
       "48841             0             0              60              0   \n",
       "\n",
       "       workclass_enc  occupation_enc  marital-status_enc  education_new_enc  \\\n",
       "0                  6               0                   4                  2   \n",
       "1                  5               3                   2                  2   \n",
       "2                  3               5                   0                  4   \n",
       "3                  3               5                   2                  6   \n",
       "4                  3               9                   2                  2   \n",
       "...              ...             ...                 ...                ...   \n",
       "48837              3               9                   0                  2   \n",
       "48838              8              14                   6                  4   \n",
       "48839              3               9                   2                  2   \n",
       "48840              3               0                   0                  2   \n",
       "48841              4               3                   2                  2   \n",
       "\n",
       "       relationship_enc  race_enc  sex_enc  native-country_enc  income_enc  \n",
       "0                     1         4        1                  38           0  \n",
       "1                     0         4        1                  38           0  \n",
       "2                     1         4        1                  38           0  \n",
       "3                     0         2        1                  38           0  \n",
       "4                     5         2        0                   4           0  \n",
       "...                 ...       ...      ...                 ...         ...  \n",
       "48837                 1         4        0                  38           0  \n",
       "48838                 2         2        1                  38           0  \n",
       "48839                 0         4        1                  38           0  \n",
       "48840                 3         1        1                  38           0  \n",
       "48841                 0         4        1                  38           1  \n",
       "\n",
       "[48790 rows x 13 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "36d4d929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48790 entries, 0 to 48841\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   capital-gain        48790 non-null  int64\n",
      " 1   capital-loss        48790 non-null  int64\n",
      " 2   hours-per-week      48790 non-null  int64\n",
      " 3   age_group_enc       48790 non-null  int32\n",
      " 4   workclass_enc       48790 non-null  int32\n",
      " 5   occupation_enc      48790 non-null  int32\n",
      " 6   marital-status_enc  48790 non-null  int32\n",
      " 7   education_new_enc   48790 non-null  int32\n",
      " 8   relationship_enc    48790 non-null  int32\n",
      " 9   race_enc            48790 non-null  int32\n",
      " 10  sex_enc             48790 non-null  int32\n",
      " 11  native-country_enc  48790 non-null  int32\n",
      " 12  income_enc          48790 non-null  int32\n",
      "dtypes: int32(10), int64(3)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "adultDataFrame_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "756f9de8-6678-4eb2-8610-3c97e63a67fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_enc\n",
       "0    37109\n",
       "1    11681\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame_encoded['income_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15069bc9-25c5-4430-ba94-0a94c0dbb6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48790"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37109+11681"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87c782",
   "metadata": {},
   "source": [
    "## **Oversampling to balance the data(>50k)** ##\n",
    "**class 0 is <=50k and class 1 is >50k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a3cd9401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: income_enc\n",
      "0    29746\n",
      "1     9286\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: income_enc\n",
      "0    29746\n",
      "1    29746\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'income' is the target variable with values '>50K' and '<=50K'\n",
    "X = adultDataFrame_encoded.drop(columns=['income_enc'])  # Features\n",
    "y = adultDataFrame_encoded['income_enc']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the distribution after oversampling\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Convert the resampled data back into a DataFrame\n",
    "X_resampled_df = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "y_resampled_df = pd.DataFrame(y_train_resampled, columns=['income_enc'])\n",
    "\n",
    "# Combine the features and target into a single DataFrame\n",
    "adultDataFrame_resampled = pd.concat([X_resampled_df, y_resampled_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8b655b50-8a5e-459b-994f-c06dc589e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>age_group_enc</th>\n",
       "      <th>workclass_enc</th>\n",
       "      <th>occupation_enc</th>\n",
       "      <th>marital-status_enc</th>\n",
       "      <th>education_new_enc</th>\n",
       "      <th>relationship_enc</th>\n",
       "      <th>race_enc</th>\n",
       "      <th>sex_enc</th>\n",
       "      <th>native-country_enc</th>\n",
       "      <th>income_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59487</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59489</th>\n",
       "      <td>27828</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59491</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59492 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       capital-gain  capital-loss  hours-per-week  age_group_enc  \\\n",
       "0                 0             0              40              3   \n",
       "1                 0             0              37              3   \n",
       "2                 0             0              32              0   \n",
       "3                 0             0              50              3   \n",
       "4                 0             0              40              0   \n",
       "...             ...           ...             ...            ...   \n",
       "59487             0             0              50              0   \n",
       "59488             0             0              40              0   \n",
       "59489         27828             0              60              0   \n",
       "59490             0             0              40              0   \n",
       "59491             0             0              50              0   \n",
       "\n",
       "       workclass_enc  occupation_enc  marital-status_enc  education_new_enc  \\\n",
       "0                  3               2                   0                  4   \n",
       "1                  3               0                   0                  8   \n",
       "2                  3               7                   6                  4   \n",
       "3                  3              11                   2                  4   \n",
       "4                  3               5                   2                  4   \n",
       "...              ...             ...                 ...                ...   \n",
       "59487              3              11                   2                  2   \n",
       "59488              3               2                   2                  8   \n",
       "59489              3               3                   3                  2   \n",
       "59490              3              11                   1                  4   \n",
       "59491              3              13                   2                  4   \n",
       "\n",
       "       relationship_enc  race_enc  sex_enc  native-country_enc  income_enc  \n",
       "0                     1         4        1                  38           0  \n",
       "1                     4         2        0                  38           0  \n",
       "2                     4         4        0                  38           0  \n",
       "3                     0         4        1                  12           0  \n",
       "4                     0         4        1                  38           0  \n",
       "...                 ...       ...      ...                 ...         ...  \n",
       "59487                 0         4        1                  38           1  \n",
       "59488                 0         4        1                  38           1  \n",
       "59489                 1         4        0                  36           1  \n",
       "59490                 4         4        0                  39           1  \n",
       "59491                 0         3        1                  38           1  \n",
       "\n",
       "[59492 rows x 13 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a06c3e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame_resampled['income_enc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a06324ee-6651-4cee-b603-43519b4233c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Test Results:\n",
      "              Feature    Chi2 Score\n",
      "4    relationship_enc  13599.681739\n",
      "2  marital-status_enc   3306.189221\n",
      "1   education_new_enc   2113.466381\n",
      "7             sex_enc    968.918793\n",
      "0       workclass_enc    517.948473\n",
      "6            race_enc     77.140084\n",
      "5  native-country_enc     35.330467\n",
      "3      occupation_enc     12.739240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming 'categorical_features' contains the names of encoded categorical columns\n",
    "categorical_features = ['workclass_enc', 'education_new_enc', 'marital-status_enc', \n",
    "                        'occupation_enc', 'relationship_enc', 'native-country_enc', \n",
    "                        'race_enc', 'sex_enc']\n",
    "\n",
    "# Select the data (features) for these categorical columns\n",
    "X_categorical = adultDataFrame_resampled[categorical_features]  # Extract the actual feature data\n",
    "target = adultDataFrame_resampled['income_enc']  # Target variable\n",
    "\n",
    "# Apply Chi-Square test\n",
    "chi2_selector = SelectKBest(chi2, k='all')\n",
    "chi2_selector.fit(X_categorical, target)\n",
    "\n",
    "# Get Chi-Square scores for each feature\n",
    "chi2_scores = pd.DataFrame({\n",
    "    'Feature': categorical_features,\n",
    "    'Chi2 Score': chi2_selector.scores_\n",
    "})\n",
    "\n",
    "# Print Chi-Square Test Results\n",
    "print(\"Chi-Square Test Results:\")\n",
    "print(chi2_scores.sort_values(by='Chi2 Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56e0bd3c-0039-4445-b202-c356df1638bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANOVA Test Results:\n",
      "                F-Statistic        P-Value\n",
      "age_group_enc   8788.812610   0.000000e+00\n",
      "hours-per-week  5134.050063   0.000000e+00\n",
      "capital-gain    2112.327334   0.000000e+00\n",
      "capital-loss    1327.689228  1.625130e-287\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare data for ANOVA Test (Continuous Features)\n",
    "continuous_features = ['age_group_enc', 'hours-per-week', 'capital-gain', 'capital-loss']\n",
    "\n",
    "# Perform One-Way ANOVA test between continuous features and target\n",
    "anova_results = {}\n",
    "for feature in continuous_features:\n",
    "    # Perform ANOVA\n",
    "    group_data = [adultDataFrame_resampled[adultDataFrame_resampled['income_enc'] == income_class][feature] \n",
    "                  for income_class in target.unique()]\n",
    "    f_val, p_val = stats.f_oneway(*group_data)\n",
    "    \n",
    "    anova_results[feature] = {'F-Statistic': f_val, 'P-Value': p_val}\n",
    "\n",
    "# Convert ANOVA results to DataFrame and display\n",
    "anova_df = pd.DataFrame(anova_results).T\n",
    "print(\"\\nANOVA Test Results:\")\n",
    "print(anova_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399421d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0be88e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to load and preprocess data\n",
    "# def load_and_preprocess_data(dataframe):\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     for column in dataframe.select_dtypes(include='object').columns:\n",
    "#         dataframe[column] = label_encoder.fit_transform(dataframe[column])\n",
    "#    # X = dataframe.drop('income', axis=1)\n",
    "#     X = adultDataFrame[['workclass', 'education_new', 'marital-status', 'relationship','sex','age', 'hours-per-week', 'capital-gain']]\n",
    "#     y = dataframe['income']\n",
    "#     return X, y\n",
    "\n",
    "\n",
    "# # Function to scale data for specific models\n",
    "# def scale_data(X_train, X_test):\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "#     return X_train_scaled, X_test_scaled\n",
    "\n",
    "# # Function to train and evaluate models\n",
    "# def train_and_evaluate_models(X_train, X_test, y_train, y_test, scale_models=[]):\n",
    "#     models = {\n",
    "#         'Logistic Regression': LogisticRegression(),\n",
    "#         'Decision Tree': DecisionTreeClassifier(),\n",
    "#         'Random Forest': RandomForestClassifier(),\n",
    "#         'XGB Boosting': XGBClassifier(),\n",
    "#         'SVM': SVC(),\n",
    "#         'Naive Bayes': GaussianNB(),\n",
    "#         'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "#     }\n",
    "    \n",
    "#     results = {}\n",
    "\n",
    "#     for model_name, model in models.items():\n",
    "#         # Scale input if the model is in the list of scale_models\n",
    "#         if model_name in scale_models:\n",
    "#             model.fit(X_train_scaled, y_train)\n",
    "#             y_pred = model.predict(X_test_scaled)\n",
    "#         else:\n",
    "#             model.fit(X_train, y_train)\n",
    "#             y_pred = model.predict(X_test)\n",
    "        \n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "#         precision = precision_score(y_test, y_pred)\n",
    "        \n",
    "#         # Store the results\n",
    "#         results[model_name] = {\n",
    "#             'Accuracy': accuracy,\n",
    "#             'Precision': precision\n",
    "#         }\n",
    "\n",
    "#         # Print classification report\n",
    "#         print(f\"{model_name} Classification Report:\\n\")\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "#         print('-' * 60)\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # Function to display results\n",
    "# def display_results(results):\n",
    "#     results_df = pd.DataFrame(results).T\n",
    "#     print(\"\\nOverall Model Performance:\")\n",
    "#     print(results_df)\n",
    "\n",
    "# # Main function to execute the process\n",
    "# def main(adultDataFrame):\n",
    "#     X, y = load_and_preprocess_data(adultDataFrame)\n",
    "    \n",
    "#     # Split data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "#     # Scale the data for models that require it (SVM, KNN)\n",
    "#     global X_train_scaled, X_test_scaled\n",
    "#     X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "\n",
    "#     # Evaluate models\n",
    "#     scale_models = ['SVM', 'K-Nearest Neighbors']\n",
    "#     results = train_and_evaluate_models(X_train, X_test, y_train, y_test, scale_models=scale_models)\n",
    "    \n",
    "#     # Display the results\n",
    "#     display_results(results)\n",
    "\n",
    "\n",
    "# main(adultDataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "66e5969c-4234-42ec-9d24-4c5e3aef7f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      8875\n",
      "           1       0.73      0.77      0.75      8973\n",
      "\n",
      "    accuracy                           0.74     17848\n",
      "   macro avg       0.74      0.74      0.74     17848\n",
      "weighted avg       0.74      0.74      0.74     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "Decision Tree Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84      8875\n",
      "           1       0.83      0.87      0.85      8973\n",
      "\n",
      "    accuracy                           0.84     17848\n",
      "   macro avg       0.84      0.84      0.84     17848\n",
      "weighted avg       0.84      0.84      0.84     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      8875\n",
      "           1       0.84      0.88      0.86      8973\n",
      "\n",
      "    accuracy                           0.86     17848\n",
      "   macro avg       0.86      0.86      0.86     17848\n",
      "weighted avg       0.86      0.86      0.86     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "XGB Boosting Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86      8875\n",
      "           1       0.84      0.89      0.87      8973\n",
      "\n",
      "    accuracy                           0.86     17848\n",
      "   macro avg       0.86      0.86      0.86     17848\n",
      "weighted avg       0.86      0.86      0.86     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "Neural Network Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      8875\n",
      "           1       0.79      0.84      0.81      8973\n",
      "\n",
      "    accuracy                           0.81     17848\n",
      "   macro avg       0.81      0.81      0.81     17848\n",
      "weighted avg       0.81      0.81      0.81     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "Naive Bayes Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.93      0.74      8875\n",
      "           1       0.87      0.43      0.57      8973\n",
      "\n",
      "    accuracy                           0.68     17848\n",
      "   macro avg       0.74      0.68      0.66     17848\n",
      "weighted avg       0.74      0.68      0.66     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "K-Nearest Neighbors Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      8875\n",
      "           1       0.83      0.84      0.84      8973\n",
      "\n",
      "    accuracy                           0.83     17848\n",
      "   macro avg       0.83      0.83      0.83     17848\n",
      "weighted avg       0.83      0.83      0.83     17848\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Overall Model Performance:\n",
      "                     Accuracy  Precision\n",
      "Logistic Regression  0.739971   0.728722\n",
      "Decision Tree        0.844184   0.829572\n",
      "Random Forest        0.857183   0.839894\n",
      "XGB Boosting         0.862113   0.844623\n",
      "Neural Network       0.807766   0.789732\n",
      "Naive Bayes          0.680244   0.866637\n",
      "K-Nearest Neighbors  0.832250   0.825476\n"
     ]
    }
   ],
   "source": [
    "# Function to load and preprocess data\n",
    "# ALl 12 features included\n",
    "# X = adultDataFrame_resampled[['workclass_enc', 'education_new_enc', 'marital-status_enc', \n",
    "#                         'occupation_enc', 'relationship_enc', 'native-country_enc', \n",
    "#                         'race_enc', 'sex_enc','capital-gain','capital-loss','age_group_enc', 'hours-per-week']]\n",
    "# features  included as per chi- square and annova test\n",
    "X = adultDataFrame_resampled[['workclass_enc', 'education_new_enc', 'marital-status_enc', \n",
    "                        'occupation_enc', 'relationship_enc',  \n",
    "                         'sex_enc','capital-gain','age_group_enc', 'hours-per-week']]\n",
    "#Removing last 3 from chi square and 1 from annova test result\n",
    "# X = adultDataFrame_resampled[['workclass_enc', 'education_new_enc', 'marital-status_enc', \n",
    "#                          'relationship_enc',  \n",
    "#                          'sex_enc','capital-gain','age_group_enc', 'hours-per-week']]\n",
    "\n",
    "y = adultDataFrame_resampled['income_enc']\n",
    "   \n",
    "\n",
    "\n",
    "# Function to scale data for specific models\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, scale_models=[]):\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'XGB Boosting': XGBClassifier(),\n",
    "        #'SVM': SVC(),\n",
    "        'Neural Network':MLPClassifier(),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Scale input if the model is in the list of scale_models\n",
    "        if model_name in scale_models:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        \n",
    "        # Store the results\n",
    "        results[model_name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision\n",
    "        }\n",
    "\n",
    "        # Print classification report\n",
    "        print(f\"{model_name} Classification Report:\\n\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('-' * 60)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to display results\n",
    "def display_results(results):\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    print(\"\\nOverall Model Performance:\")\n",
    "    print(results_df)\n",
    "\n",
    "# Main function to execute the process\n",
    "def main(adultDataFrame):\n",
    "   \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Scale the data for models that require it (SVM, KNN)\n",
    "    global X_train_scaled, X_test_scaled\n",
    "    X_train_scaled, X_test_scaled = scale_data(X_train, X_test)\n",
    "\n",
    "    # Evaluate models\n",
    "    #scale_models = ['SVM', 'K-Nearest Neighbors']\n",
    "    scale_models = ['K-Nearest Neighbors']\n",
    "    results = train_and_evaluate_models(X_train, X_test, y_train, y_test, scale_models=scale_models)\n",
    "    \n",
    "    # Display the results\n",
    "    display_results(results)\n",
    "\n",
    "\n",
    "main(adultDataFrame_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512844b0-1f7a-404a-832f-4a983d19f37f",
   "metadata": {},
   "source": [
    "### output based on all 12 features\n",
    " Overall Model Performance:\n",
    "                     Accuracy  Precision\n",
    "Logistic Regression  0.745798   0.733572\n",
    "Decision Tree        0.855726   0.839236\n",
    "Random Forest        0.871526   0.854264\n",
    "XGB Boosting         0.872367   0.853671\n",
    "Neural Network       0.794207   0.732947\n",
    "Naive Bayes          0.661811   0.865026\n",
    "K-Nearest Neighbors  0.837517   0.819396 \n",
    "\n",
    "### output based on feature from chi square and annova test\n",
    "Overall Model Performance:\n",
    "                     Accuracy  Precision\n",
    "Logistic Regression  0.739971   0.728722\n",
    "Decision Tree        0.844745   0.830245\n",
    "Random Forest        0.856342   0.839856\n",
    "XGB Boosting         0.862113   0.844623\n",
    "Neural Network       0.803171   0.773712\n",
    "Naive Bayes          0.680244   0.866637\n",
    "K-Nearest Neighbors  0.832250   0.825476 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f569728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [10:14:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50}\n",
      "Best Score: 0.873821439932452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# # Define the model\n",
    "# rf = RandomForestClassifier()\n",
    "# # Define hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'max_depth': [5, 10, 20, None],\n",
    "#     'min_samples_split': [2, 10, 20],\n",
    "#     'min_samples_leaf': [1, 5, 10],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "# # Set up GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# # Best parameters and score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# print(f\"Best Score: {best_score}\")\n",
    "\n",
    "\n",
    "\n",
    "# 'income' is the target variable and other features are in 'X'\n",
    "X = adultDataFrame.drop(columns=['income'])  # Features\n",
    "y = adultDataFrame['income']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline([\n",
    "   # ('classifier', RandomForestClassifier())\n",
    "     ('classifier',XGBClassifier())\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a5683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17f08eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Model: RandomForestClassifier\n",
      "Best Parameters: {'classifier': RandomForestClassifier(), 'classifier__max_depth': 20, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "Best Score (Accuracy): 0.8641\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Model: XGBClassifier\n",
      "Best Parameters: {'classifier': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), 'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_child_weight': 2, 'classifier__n_estimators': 200}\n",
      "Best Score (Accuracy): 0.8751\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Best Parameters: {'classifier': LogisticRegression(max_iter=500), 'classifier__C': 1, 'classifier__solver': 'liblinear'}\n",
      "Best Score (Accuracy): 0.8065\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Model: DecisionTreeClassifier\n",
      "Best Parameters: {'classifier': DecisionTreeClassifier(), 'classifier__max_depth': 10, 'classifier__min_samples_split': 10}\n",
      "Best Score (Accuracy): 0.8540\n",
      "Metrics for RandomForestClassifier:\n",
      "  Test Accuracy: 0.8598\n",
      "  Precision: 0.7687\n",
      "Metrics for XGBClassifier:\n",
      "  Test Accuracy: 0.8700\n",
      "  Precision: 0.7736\n",
      "Metrics for LogisticRegression:\n",
      "  Test Accuracy: 0.8007\n",
      "  Precision: 0.7296\n",
      "Metrics for DecisionTreeClassifier:\n",
      "  Test Accuracy: 0.8494\n",
      "  Precision: 0.7551\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "# Prepare features and target variable\n",
    "X = adultDataFrame.drop(columns=['income'])  # Features\n",
    "y = adultDataFrame['income']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of classifiers and their corresponding parameter grids\n",
    "models_param_grids = [\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    {\n",
    "        'classifier': [XGBClassifier()],\n",
    "        'classifier__n_estimators': [50, 100, 150, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 4, 5],\n",
    "        'classifier__min_child_weight': [1,2,3,4,5]\n",
    "    },    \n",
    "#     {\n",
    "#         'classifier': [SVC()],\n",
    "#         'classifier__C': [0.1, 1, 10],\n",
    "#         'classifier__kernel': ['linear', 'rbf']\n",
    "#     },\n",
    "    {\n",
    "        'classifier': [LogisticRegression(max_iter=500)],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Loop through models and perform hyperparameter tuning\n",
    "best_models = []\n",
    "for param_grid in models_param_grids:\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', param_grid['classifier'][0])\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model and parameters for the current classifier\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"Model: {param_grid['classifier'][0].__class__.__name__}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best Score (Accuracy): {best_score:.4f}\")\n",
    "    \n",
    "    # Save the best model from each classifier\n",
    "    best_models.append((best_model, best_score))\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "for model, score in best_models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "#     test_recall = recall_score(y_test, y_pred)\n",
    "#     test_f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    classifier_name = model.named_steps['classifier'].__class__.__name__\n",
    "    print(f\"Metrics for {classifier_name}:\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"  Precision: {test_precision:.4f}\")\n",
    "#     print(f\"  Recall: {test_recall:.4f}\")\n",
    "#     print(f\"  F1 Score: {test_f1:.4f}\")\n",
    "    \n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "#     print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     print(\"-\" * 40)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eb5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Model: RandomForestClassifier\n",
      "Best Parameters: {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=7, n_estimators=102), 'classifier__max_depth': 20, 'classifier__min_samples_split': 7, 'classifier__n_estimators': 102}\n",
      "Best Score (Accuracy): 0.8645\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Model: GradientBoostingClassifier\n",
      "Best Parameters: {'classifier': GradientBoostingClassifier(learning_rate=0.2, max_depth=4, min_samples_split=6,\n",
      "                           n_estimators=70), 'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 70}\n",
      "Best Score (Accuracy): 0.8747\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "# Prepare features and target variable\n",
    "X = adultDataFrame.drop(columns=['income'])  # Features\n",
    "y = adultDataFrame['income']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of classifiers and their corresponding random search parameter distributions\n",
    "models_param_distributions = [\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': randint(50, 200),\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': randint(2, 10)\n",
    "    },\n",
    "    {\n",
    "        'classifier': [XGBClassifier()],\n",
    "        'classifier__n_estimators': randint(50, 200),\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': randint(3, 5),\n",
    "        'classifier__min_child_weight': randint(1, 6)\n",
    "    },\n",
    "    {\n",
    "        'classifier': [SVC()],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    {\n",
    "        'classifier': [LogisticRegression(max_iter=500)],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    {\n",
    "        'classifier': [DecisionTreeClassifier()],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': randint(2, 10)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Loop through models and perform hyperparameter tuning using RandomizedSearchCV\n",
    "best_models = []\n",
    "for param_distribution in models_param_distributions:\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', param_distribution['classifier'][0])\n",
    "    ])\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        pipeline, \n",
    "        param_distribution, \n",
    "        cv=5, \n",
    "        n_iter=10,  # Number of parameter settings to sample\n",
    "        n_jobs=-1, \n",
    "        verbose=1, \n",
    "        scoring='accuracy',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Best model and parameters for the current classifier\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "    best_model = random_search.best_estimator_\n",
    "    \n",
    "    print(f\"Model: {param_distribution['classifier'][0].__class__.__name__}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Best Score (Accuracy): {best_score:.4f}\")\n",
    "    \n",
    "    # Save the best model from each classifier\n",
    "    best_models.append((best_model, best_score))\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "for model, score in best_models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {model.named_steps['classifier'].__class__.__name__}: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
    "Model: RandomForestClassifier\n",
    "Best Parameters: {'classifier': RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=200), 'classifier__max_depth': 20, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
    "Best Score (Accuracy): 0.8643\n",
    "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
    "Model: GradientBoostingClassifier\n",
    "Best Parameters: {'classifier': GradientBoostingClassifier(max_depth=5, min_samples_split=5), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
    "Best Score (Accuracy): 0.8754\n",
    "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
    "Model: LogisticRegression\n",
    "Best Parameters: {'classifier': LogisticRegression(C=10, max_iter=500, solver='liblinear'), 'classifier__C': 10, 'classifier__solver': 'liblinear'}\n",
    "Best Score (Accuracy): 0.8065\n",
    "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
    "Model: DecisionTreeClassifier\n",
    "Best Parameters: {'classifier': DecisionTreeClassifier(max_depth=10, min_samples_split=10), 'classifier__max_depth': 10, 'classifier__min_samples_split': 10}\n",
    "Best Score (Accuracy): 0.8539\n",
    "Test Accuracy for RandomForestClassifier: 0.8597\n",
    "Test Accuracy for GradientBoostingClassifier: 0.8680\n",
    "Test Accuracy for LogisticRegression: 0.8024\n",
    "Test Accuracy for DecisionTreeClassifier: 0.8494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4712ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7638f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1e159-3fd4-4f01-8fbd-c1d545d91524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d927d8-aca1-4b3e-ba51-efafeba8ab24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf86da1e-d3bc-46be-8f39-7e2ab9991cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'State-gov'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Exploratory Data Analysis (EDA)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Correlation analysis (only for numeric features)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43madultDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10702\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10703\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10704\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10707\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'State-gov'"
     ]
    }
   ],
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "# Correlation analysis (only for numeric features)\n",
    "sns.heatmap(adultDataFrame.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9113ba-7275-4cdb-983c-755b7080cf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4440dd1-9cd1-4d1d-8bd1-4c8553337cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Training Setup\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524582a-5cc3-43c4-9ff3-199e4a66a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model Explanation and Execution (RandomForestClassifier with hyperparameter tuning)\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e26ca-fef1-4461-87c5-efea57f959ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Best parameters found by grid search\n",
    "print(\"\\nBest Hyperparameters:\\n\", grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
