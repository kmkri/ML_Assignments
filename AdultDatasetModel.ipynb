{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7320245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (2.1.1)\r\n",
      "Requirement already satisfied: scipy in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (2.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e54f1187-3b0f-411b-abf0-87f28bb73405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d94a27b-7f17-44d1-9dbf-3d00c467e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from ucimlrepo) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2.0.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sravanthithiruveedi/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Installing ucimlrepo package\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a79b87ce-1134-45e2-833a-212c6300ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "The following datasets are available:\n",
      "-------------------------------------\n",
      "Dataset Name                                                                            ID    \n",
      "------------                                                                            --    \n",
      "Abalone                                                                                 1     \n",
      "Adult                                                                                   2     \n",
      "Annealing                                                                               3     \n",
      "Audiology (Standardized)                                                                8     \n",
      "Auto MPG                                                                                9     \n",
      "Automobile                                                                              10    \n",
      "Balance Scale                                                                           12    \n",
      "Balloons                                                                                13    \n",
      "Breast Cancer                                                                           14    \n",
      "Breast Cancer Wisconsin (Original)                                                      15    \n",
      "Breast Cancer Wisconsin (Prognostic)                                                    16    \n",
      "Breast Cancer Wisconsin (Diagnostic)                                                    17    \n",
      "Pittsburgh Bridges                                                                      18    \n",
      "Car Evaluation                                                                          19    \n",
      "Census Income                                                                           20    \n",
      "Chess (King-Rook vs. King-Pawn)                                                         22    \n",
      "Chess (King-Rook vs. King)                                                              23    \n",
      "Connect-4                                                                               26    \n",
      "Credit Approval                                                                         27    \n",
      "Japanese Credit Screening                                                               28    \n",
      "Computer Hardware                                                                       29    \n",
      "Contraceptive Method Choice                                                             30    \n",
      "Covertype                                                                               31    \n",
      "Cylinder Bands                                                                          32    \n",
      "Dermatology                                                                             33    \n",
      "Echocardiogram                                                                          38    \n",
      "Ecoli                                                                                   39    \n",
      "Flags                                                                                   40    \n",
      "Glass Identification                                                                    42    \n",
      "Haberman's Survival                                                                     43    \n",
      "Hayes-Roth                                                                              44    \n",
      "Heart Disease                                                                           45    \n",
      "Hepatitis                                                                               46    \n",
      "Horse Colic                                                                             47    \n",
      "Image Segmentation                                                                      50    \n",
      "Ionosphere                                                                              52    \n",
      "Iris                                                                                    53    \n",
      "ISOLET                                                                                  54    \n",
      "Lenses                                                                                  58    \n",
      "Letter Recognition                                                                      59    \n",
      "Liver Disorders                                                                         60    \n",
      "Lung Cancer                                                                             62    \n",
      "Lymphography                                                                            63    \n",
      "Molecular Biology (Splice-junction Gene Sequences)                                      69    \n",
      "MONK's Problems                                                                         70    \n",
      "Mushroom                                                                                73    \n",
      "Musk (Version 1)                                                                        74    \n",
      "Musk (Version 2)                                                                        75    \n",
      "Nursery                                                                                 76    \n",
      "Page Blocks Classification                                                              78    \n",
      "Optical Recognition of Handwritten Digits                                               80    \n",
      "Pen-Based Recognition of Handwritten Digits                                             81    \n",
      "Post-Operative Patient                                                                  82    \n",
      "Primary Tumor                                                                           83    \n",
      "Servo                                                                                   87    \n",
      "Shuttle Landing Control                                                                 88    \n",
      "Solar Flare                                                                             89    \n",
      "Soybean (Large)                                                                         90    \n",
      "Soybean (Small)                                                                         91    \n",
      "Challenger USA Space Shuttle O-Ring                                                     92    \n",
      "Spambase                                                                                94    \n",
      "SPECT Heart                                                                             95    \n",
      "SPECTF Heart                                                                            96    \n",
      "Tic-Tac-Toe Endgame                                                                     101   \n",
      "Congressional Voting Records                                                            105   \n",
      "Waveform Database Generator (Version 1)                                                 107   \n",
      "Wine                                                                                    109   \n",
      "Yeast                                                                                   110   \n",
      "Zoo                                                                                     111   \n",
      "US Census Data (1990)                                                                   116   \n",
      "Census-Income (KDD)                                                                     117   \n",
      "El Nino                                                                                 122   \n",
      "Statlog (Australian Credit Approval)                                                    143   \n",
      "Statlog (German Credit Data)                                                            144   \n",
      "Statlog (Heart)                                                                         145   \n",
      "Statlog (Landsat Satellite)                                                             146   \n",
      "Statlog (Image Segmentation)                                                            147   \n",
      "Statlog (Shuttle)                                                                       148   \n",
      "Statlog (Vehicle Silhouettes)                                                           149   \n",
      "Connectionist Bench (Sonar, Mines vs. Rocks)                                            151   \n",
      "Cloud                                                                                   155   \n",
      "Poker Hand                                                                              158   \n",
      "MAGIC Gamma Telescope                                                                   159   \n",
      "Mammographic Mass                                                                       161   \n",
      "Forest Fires                                                                            162   \n",
      "Concrete Compressive Strength                                                           165   \n",
      "Ozone Level Detection                                                                   172   \n",
      "Parkinsons                                                                              174   \n",
      "Blood Transfusion Service Center                                                        176   \n",
      "Communities and Crime                                                                   183   \n",
      "Acute Inflammations                                                                     184   \n",
      "Wine Quality                                                                            186   \n",
      "Parkinsons Telemonitoring                                                               189   \n",
      "Cardiotocography                                                                        193   \n",
      "Steel Plates Faults                                                                     198   \n",
      "Communities and Crime Unnormalized                                                      211   \n",
      "Vertebral Column                                                                        212   \n",
      "Bank Marketing                                                                          222   \n",
      "ILPD (Indian Liver Patient Dataset)                                                     225   \n",
      "Skin Segmentation                                                                       229   \n",
      "Individual Household Electric Power Consumption                                         235   \n",
      "Energy Efficiency                                                                       242   \n",
      "Fertility                                                                               244   \n",
      "ISTANBUL STOCK EXCHANGE                                                                 247   \n",
      "User Knowledge Modeling                                                                 257   \n",
      "EEG Eye State                                                                           264   \n",
      "Banknote Authentication                                                                 267   \n",
      "Gas Sensor Array Drift at Different Concentrations                                      270   \n",
      "Bike Sharing                                                                            275   \n",
      "Thoracic Surgery Data                                                                   277   \n",
      "Airfoil Self-Noise                                                                      291   \n",
      "Wholesale customers                                                                     292   \n",
      "Combined Cycle Power Plant                                                              294   \n",
      "Diabetes 130-US Hospitals for Years 1999-2008                                           296   \n",
      "Tennis Major Tournament Match Statistics                                                300   \n",
      "Dow Jones Index                                                                         312   \n",
      "Student Performance                                                                     320   \n",
      "Phishing Websites                                                                       327   \n",
      "Diabetic Retinopathy Debrecen                                                           329   \n",
      "Online News Popularity                                                                  332   \n",
      "Chronic Kidney Disease                                                                  336   \n",
      "Mice Protein Expression                                                                 342   \n",
      "Default of Credit Card Clients                                                          350   \n",
      "Online Retail                                                                           352   \n",
      "Occupancy Detection                                                                     357   \n",
      "Air Quality                                                                             360   \n",
      "Polish Companies Bankruptcy                                                             365   \n",
      "Dota2 Games Results                                                                     367   \n",
      "Facebook Metrics                                                                        368   \n",
      "HTRU2                                                                                   372   \n",
      "Drug Consumption (Quantified)                                                           373   \n",
      "Appliances Energy Prediction                                                            374   \n",
      "Website Phishing                                                                        379   \n",
      "YouTube Spam Collection                                                                 380   \n",
      "Beijing PM2.5                                                                           381   \n",
      "Cervical Cancer (Risk Factors)                                                          383   \n",
      "Stock Portfolio Performance                                                             390   \n",
      "Sales Transactions Weekly                                                               396   \n",
      "Daily Demand Forecasting Orders                                                         409   \n",
      "Autistic Spectrum Disorder Screening Data for Children                                  419   \n",
      "Autism Screening Adult                                                                  426   \n",
      "Absenteeism at work                                                                     445   \n",
      "Breast Cancer Coimbra                                                                   451   \n",
      "Drug Reviews (Druglib.com)                                                              461   \n",
      "Drug Reviews (Drugs.com)                                                                462   \n",
      "Superconductivty Data                                                                   464   \n",
      "Student Academics Performance                                                           467   \n",
      "Online Shoppers Purchasing Intention Dataset                                            468   \n",
      "Electrical Grid Stability Simulated Data                                                471   \n",
      "Real Estate Valuation                                                                   477   \n",
      "Travel Reviews                                                                          484   \n",
      "Travel Review Ratings                                                                   485   \n",
      "Facebook Live Sellers in Thailand                                                       488   \n",
      "Metro Interstate Traffic Volume                                                         492   \n",
      "Hepatitis C Virus (HCV) for Egyptian patients                                           503   \n",
      "Heart Failure Clinical Records                                                          519   \n",
      "Early Stage Diabetes Risk Prediction                                                    529   \n",
      "Pedestrians in Traffic                                                                  536   \n",
      "Cervical Cancer Behavior Risk                                                           537   \n",
      "Estimation of Obesity Levels Based On Eating Habits and Physical Condition              544   \n",
      "Rice (Cammeo and Osmancik)                                                              545   \n",
      "Algerian Forest Fires                                                                   547   \n",
      "Gas Turbine CO and NOx Emission Data Set                                                551   \n",
      "Apartment for Rent Classified                                                           555   \n",
      "Seoul Bike Sharing Demand                                                               560   \n",
      "Iranian Churn                                                                           563   \n",
      "Bone marrow transplant: children                                                        565   \n",
      "COVID-19 Surveillance                                                                   567   \n",
      "HCV data                                                                                571   \n",
      "Taiwanese Bankruptcy Prediction                                                         572   \n",
      "Myocardial infarction complications                                                     579   \n",
      "Student Performance on an Entrance Examination                                          582   \n",
      "Gender by Name                                                                          591   \n",
      "Productivity Prediction of Garment Employees                                            597   \n",
      "AI4I 2020 Predictive Maintenance Dataset                                                601   \n",
      "Dry Bean                                                                                602   \n",
      "In-Vehicle Coupon Recommendation                                                        603   \n",
      "Predict Students' Dropout and Academic Success                                          697   \n",
      "Auction Verification                                                                    713   \n",
      "NATICUSdroid (Android Permissions)                                                      722   \n",
      "Toxicity                                                                                728   \n",
      "DARWIN                                                                                  732   \n",
      "Accelerometer Gyro Mobile Phone                                                         755   \n",
      "Glioma Grading Clinical and Mutation Features                                           759   \n",
      "Multivariate Gait Data                                                                  760   \n",
      "Land Mines                                                                              763   \n",
      "Single Elder Home Monitoring: Gas and Position                                          799   \n",
      "Sepsis Survival Minimal Clinical Records                                                827   \n",
      "Secondary Mushroom                                                                      848   \n",
      "Power Consumption of Tetouan City                                                       849   \n",
      "Raisin                                                                                  850   \n",
      "Steel Industry Energy Consumption                                                       851   \n",
      "Higher Education Students Performance Evaluation                                        856   \n",
      "Risk Factor Prediction of Chronic Kidney Disease                                        857   \n",
      "Maternal Health Risk                                                                    863   \n",
      "Room Occupancy Estimation                                                               864   \n",
      "Cirrhosis Patient Survival Prediction                                                   878   \n",
      "SUPPORT2                                                                                880   \n",
      "National Health and Nutrition Health Survey 2013-2014 (NHANES) Age Prediction Subset    887   \n",
      "AIDS Clinical Trials Group Study 175                                                    890   \n",
      "CDC Diabetes Health Indicators                                                          891   \n",
      "Recipe Reviews and User Feedback                                                        911   \n",
      "Forty Soybean Cultivars from Subsequent Harvests                                        913   \n",
      "Differentiated Thyroid Cancer Recurrence                                                915   \n",
      "Infrared Thermography Temperature                                                       925   \n",
      "National Poll on Healthy Aging (NPHA)                                                   936   \n",
      "Regensburg Pediatric Appendicitis                                                       938   \n",
      "RT-IoT2022                                                                              942   \n",
      "PhiUSIIL Phishing URL (Website)                                                         967   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fetching UCI repositories \n",
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "#List of UCI repositories with ID\n",
    "list_available_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d31a206-b8b0-4374-91a7-dfbbaef81852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country  income  \n",
       "0      United-States   <=50K  \n",
       "1      United-States   <=50K  \n",
       "2      United-States   <=50K  \n",
       "3      United-States   <=50K  \n",
       "4               Cuba   <=50K  \n",
       "...              ...     ...  \n",
       "48837  United-States  <=50K.  \n",
       "48838  United-States  <=50K.  \n",
       "48839  United-States  <=50K.  \n",
       "48840  United-States  <=50K.  \n",
       "48841  United-States   >50K.  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch dataset and create dataframe\n",
    "adult = fetch_ucirepo(id=2) \n",
    "adultDataFrame = adult.data.original\n",
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9287ab4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       "Private             33906\n",
       "Self-emp-not-inc     3862\n",
       "Local-gov            3136\n",
       "State-gov            1981\n",
       "?                    1836\n",
       "Self-emp-inc         1695\n",
       "Federal-gov          1432\n",
       "Without-pay            21\n",
       "Never-worked           10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originaldataset = adultDataFrame\n",
    "originaldataset['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39fa66b2-ecc9-433b-bcc8-2327de7d8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adultDataFrame1.replace('?', np.nan, inplace=True)\n",
    "# # Clean values in income column\n",
    "# adultDataFrame1['income'].replace('<=50K.', '<=50K',inplace = True)\n",
    "# adultDataFrame1['income'].replace('>50K.', '>50K',inplace = True)\n",
    "\n",
    "# print(\"Duplicate Rows:\\n\", adultDataFrame1.duplicated().sum())\n",
    "# duplicates  = adultDataFrame1[adultDataFrame1.duplicated()]\n",
    "# duplicates\n",
    "# duplicates[duplicates['fnlwgt']== 308144]\n",
    "# #Check and drop duplicates\n",
    "# adult_cleanedData = adultDataFrame1.drop_duplicates(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6f5b2ff-36ca-474a-a8fd-7e683d5ec043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      " 29\n",
      "Blank Rows (All NaN values): 0\n",
      "Duplicate Rows:\n",
      " 52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt  education  education-num  \\\n",
       "0       39         State-gov   77516  Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2       38           Private  215646    HS-grad              9   \n",
       "3       53           Private  234721       11th              7   \n",
       "4       28           Private  338409  Bachelors             13   \n",
       "...    ...               ...     ...        ...            ...   \n",
       "48837   39           Private  215419  Bachelors             13   \n",
       "48838   64               NaN  321403    HS-grad              9   \n",
       "48839   38           Private  374983  Bachelors             13   \n",
       "48840   44           Private   83891  Bachelors             13   \n",
       "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                NaN  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male          2174             0              40   \n",
       "1                   White    Male             0             0              13   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male             0             0              40   \n",
       "4                   Black  Female             0             0              40   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "48837               White  Female             0             0              36   \n",
       "48838               Black    Male             0             0              40   \n",
       "48839               White    Male             0             0              50   \n",
       "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
       "48841               White    Male             0             0              60   \n",
       "\n",
       "      native-country income  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3      United-States  <=50K  \n",
       "4               Cuba  <=50K  \n",
       "...              ...    ...  \n",
       "48837  United-States  <=50K  \n",
       "48838  United-States  <=50K  \n",
       "48839  United-States  <=50K  \n",
       "48840  United-States  <=50K  \n",
       "48841  United-States   >50K  \n",
       "\n",
       "[48790 rows x 15 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Data Cleaning\n",
    "print(\"Duplicate Rows:\\n\", adultDataFrame.duplicated().sum())\n",
    "# Identify rows where all values are NaN\n",
    "# Identify rows where all values are NaN\n",
    "blank_rows = adultDataFrame.isnull().all(axis=1)\n",
    "\n",
    "# Print the count of blank rows\n",
    "print(\"Blank Rows (All NaN values):\", blank_rows.sum())\n",
    "# Handling missing values ('?' is treated as missing in this dataset)\n",
    "adultDataFrame.replace('?', np.nan, inplace=True)\n",
    "\n",
    "#Check and drop duplicates\n",
    "# adult_cleanedData = adultDataFrame1.drop_duplicates(inplace=False)\n",
    "\n",
    " \n",
    "\n",
    "# Clean values in income column\n",
    "adultDataFrame['income'].replace('<=50K.', '<=50K',inplace = True)\n",
    "adultDataFrame['income'].replace('>50K.', '>50K',inplace = True)\n",
    "#adult_cleanedData\n",
    "adultDataFrame['income'].value_counts()\n",
    "\n",
    "print(\"Duplicate Rows:\\n\", adultDataFrame.duplicated().sum())\n",
    "duplicates  = adultDataFrame[adultDataFrame.duplicated()]\n",
    "#duplicates\n",
    "# #Check and drop duplicates\n",
    "#adult_cleanedData = adultDataFrame.drop_duplicates(inplace=False)\n",
    "adultDataFrame.drop_duplicates(inplace=True)\n",
    "\n",
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "748b920a-cc18-405d-a206-5469229db3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_new  education   \n",
       "HS-grad        HS-grad         15770\n",
       "Some-college   Some-college    10863\n",
       "Bachelors      Bachelors        8013\n",
       "Masters        Masters          2656\n",
       "Assoc-voc      Assoc-voc        2060\n",
       "High-School    11th             1812\n",
       "Assoc-acdm     Assoc-acdm       1601\n",
       "High-School    10th             1389\n",
       "Middle-School  7th-8th           954\n",
       "Prof-school    Prof-school       834\n",
       "High-School    9th               756\n",
       "               12th              655\n",
       "Doctorate      Doctorate         594\n",
       "Elementary     5th-6th           507\n",
       "               1st-4th           245\n",
       "               Preschool          81\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['education_new'] = np.where(np.isin(adultDataFrame.education,['Preschool','1st-4th','5th-6th']),'Elementary',\n",
    "                           np.where(np.isin(adultDataFrame.education,['7th-8th']),'Middle-School',\n",
    "                           np.where(np.isin(adultDataFrame.education,['9th','10th','11th','12th']),'High-School',adultDataFrame.education)))\n",
    "adultDataFrame[['education_new','education']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fccaa60f-2514-40b1-9332-7ddb4695f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the column which are not needed\n",
    "adultDataFrame.drop(columns=['fnlwgt','education','education-num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "998e2900-f500-4aef-ba5c-a6ca01342ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>education_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>High-School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>HS-grad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Bachelors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass      marital-status         occupation  \\\n",
       "0       39         State-gov       Never-married       Adm-clerical   \n",
       "1       50  Self-emp-not-inc  Married-civ-spouse    Exec-managerial   \n",
       "2       38           Private            Divorced  Handlers-cleaners   \n",
       "3       53           Private  Married-civ-spouse  Handlers-cleaners   \n",
       "4       28           Private  Married-civ-spouse     Prof-specialty   \n",
       "...    ...               ...                 ...                ...   \n",
       "48837   39           Private            Divorced     Prof-specialty   \n",
       "48838   64               NaN             Widowed                NaN   \n",
       "48839   38           Private  Married-civ-spouse     Prof-specialty   \n",
       "48840   44           Private            Divorced       Adm-clerical   \n",
       "48841   35      Self-emp-inc  Married-civ-spouse    Exec-managerial   \n",
       "\n",
       "         relationship                race     sex  capital-gain  capital-loss  \\\n",
       "0       Not-in-family               White    Male          2174             0   \n",
       "1             Husband               White    Male             0             0   \n",
       "2       Not-in-family               White    Male             0             0   \n",
       "3             Husband               Black    Male             0             0   \n",
       "4                Wife               Black  Female             0             0   \n",
       "...               ...                 ...     ...           ...           ...   \n",
       "48837   Not-in-family               White  Female             0             0   \n",
       "48838  Other-relative               Black    Male             0             0   \n",
       "48839         Husband               White    Male             0             0   \n",
       "48840       Own-child  Asian-Pac-Islander    Male          5455             0   \n",
       "48841         Husband               White    Male             0             0   \n",
       "\n",
       "       hours-per-week native-country income education_new  \n",
       "0                  40  United-States  <=50K     Bachelors  \n",
       "1                  13  United-States  <=50K     Bachelors  \n",
       "2                  40  United-States  <=50K       HS-grad  \n",
       "3                  40  United-States  <=50K   High-School  \n",
       "4                  40           Cuba  <=50K     Bachelors  \n",
       "...               ...            ...    ...           ...  \n",
       "48837              36  United-States  <=50K     Bachelors  \n",
       "48838              40  United-States  <=50K       HS-grad  \n",
       "48839              50  United-States  <=50K     Bachelors  \n",
       "48840              40  United-States  <=50K     Bachelors  \n",
       "48841              60  United-States   >50K     Bachelors  \n",
       "\n",
       "[48790 rows x 13 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb227344-cb81-4f53-a9d3-c485a12fb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 13 16 45 50 80 30 35 60 20 52 44 15 25 38 43 55 48 58 32 70  2 22 56\n",
      " 41 28 36 24 46 42 12 65  1 10 34 75 33 54  8  6 64 19 18 72  5  9 47 37\n",
      " 21 26 14  4 59  7 53 39 62 57 78 66 11 49  3 17 68 27 31 51 77 63 23 73\n",
      " 29 67 76 61 74 79 69]\n"
     ]
    }
   ],
   "source": [
    "# Cap 'hours-per-week' at 80adultDataFrame\n",
    "adultDataFrame['hours-per-week'] = adultDataFrame['hours-per-week'].apply(lambda x: 80 if x > 80 else x)\n",
    "\n",
    "# Verify the changes\n",
    "print(adultDataFrame['hours-per-week'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc997bc3-3314-4755-9493-dc2afbd48644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode_columns = ['workclass','occupation','marital-status','education_new','relationship','race','sex','native-country','income']\n",
    "\n",
    "for column in encode_columns:\n",
    " adultDataFrame[column+'_enc'] = LabelEncoder().fit_transform(adultDataFrame[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d271c194-b6a5-496b-bc74-e034818da563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>...</th>\n",
       "      <th>education_new</th>\n",
       "      <th>workclass_enc</th>\n",
       "      <th>occupation_enc</th>\n",
       "      <th>marital-status_enc</th>\n",
       "      <th>education_new_enc</th>\n",
       "      <th>relationship_enc</th>\n",
       "      <th>race_enc</th>\n",
       "      <th>sex_enc</th>\n",
       "      <th>native-country_enc</th>\n",
       "      <th>income_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>High-School</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass      marital-status         occupation  \\\n",
       "0       39         State-gov       Never-married       Adm-clerical   \n",
       "1       50  Self-emp-not-inc  Married-civ-spouse    Exec-managerial   \n",
       "2       38           Private            Divorced  Handlers-cleaners   \n",
       "3       53           Private  Married-civ-spouse  Handlers-cleaners   \n",
       "4       28           Private  Married-civ-spouse     Prof-specialty   \n",
       "...    ...               ...                 ...                ...   \n",
       "48837   39           Private            Divorced     Prof-specialty   \n",
       "48838   64               NaN             Widowed                NaN   \n",
       "48839   38           Private  Married-civ-spouse     Prof-specialty   \n",
       "48840   44           Private            Divorced       Adm-clerical   \n",
       "48841   35      Self-emp-inc  Married-civ-spouse    Exec-managerial   \n",
       "\n",
       "         relationship                race     sex  capital-gain  capital-loss  \\\n",
       "0       Not-in-family               White    Male          2174             0   \n",
       "1             Husband               White    Male             0             0   \n",
       "2       Not-in-family               White    Male             0             0   \n",
       "3             Husband               Black    Male             0             0   \n",
       "4                Wife               Black  Female             0             0   \n",
       "...               ...                 ...     ...           ...           ...   \n",
       "48837   Not-in-family               White  Female             0             0   \n",
       "48838  Other-relative               Black    Male             0             0   \n",
       "48839         Husband               White    Male             0             0   \n",
       "48840       Own-child  Asian-Pac-Islander    Male          5455             0   \n",
       "48841         Husband               White    Male             0             0   \n",
       "\n",
       "       hours-per-week  ... education_new workclass_enc occupation_enc  \\\n",
       "0                  40  ...     Bachelors             6              0   \n",
       "1                  13  ...     Bachelors             5              3   \n",
       "2                  40  ...       HS-grad             3              5   \n",
       "3                  40  ...   High-School             3              5   \n",
       "4                  40  ...     Bachelors             3              9   \n",
       "...               ...  ...           ...           ...            ...   \n",
       "48837              36  ...     Bachelors             3              9   \n",
       "48838              40  ...       HS-grad             8             14   \n",
       "48839              50  ...     Bachelors             3              9   \n",
       "48840              40  ...     Bachelors             3              0   \n",
       "48841              60  ...     Bachelors             4              3   \n",
       "\n",
       "       marital-status_enc  education_new_enc  relationship_enc  race_enc  \\\n",
       "0                       4                  2                 1         4   \n",
       "1                       2                  2                 0         4   \n",
       "2                       0                  5                 1         4   \n",
       "3                       2                  6                 0         2   \n",
       "4                       2                  2                 5         2   \n",
       "...                   ...                ...               ...       ...   \n",
       "48837                   0                  2                 1         4   \n",
       "48838                   6                  5                 2         2   \n",
       "48839                   2                  2                 0         4   \n",
       "48840                   0                  2                 3         1   \n",
       "48841                   2                  2                 0         4   \n",
       "\n",
       "       sex_enc  native-country_enc  income_enc  \n",
       "0            1                  38           0  \n",
       "1            1                  38           0  \n",
       "2            1                  38           0  \n",
       "3            1                  38           0  \n",
       "4            0                   4           0  \n",
       "...        ...                 ...         ...  \n",
       "48837        0                  38           0  \n",
       "48838        1                  38           0  \n",
       "48839        1                  38           0  \n",
       "48840        1                  38           0  \n",
       "48841        1                  38           1  \n",
       "\n",
       "[48790 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8594394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2795)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['workclass'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36d4d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 48790 entries, 0 to 48841\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   age                 48790 non-null  int64 \n",
      " 1   workclass           45995 non-null  object\n",
      " 2   marital-status      48790 non-null  object\n",
      " 3   occupation          45985 non-null  object\n",
      " 4   relationship        48790 non-null  object\n",
      " 5   race                48790 non-null  object\n",
      " 6   sex                 48790 non-null  object\n",
      " 7   capital-gain        48790 non-null  int64 \n",
      " 8   capital-loss        48790 non-null  int64 \n",
      " 9   hours-per-week      48790 non-null  int64 \n",
      " 10  native-country      47934 non-null  object\n",
      " 11  income              48790 non-null  object\n",
      " 12  education_new       48790 non-null  object\n",
      " 13  workclass_enc       48790 non-null  int64 \n",
      " 14  occupation_enc      48790 non-null  int64 \n",
      " 15  marital-status_enc  48790 non-null  int64 \n",
      " 16  education_new_enc   48790 non-null  int64 \n",
      " 17  relationship_enc    48790 non-null  int64 \n",
      " 18  race_enc            48790 non-null  int64 \n",
      " 19  sex_enc             48790 non-null  int64 \n",
      " 20  native-country_enc  48790 non-null  int64 \n",
      " 21  income_enc          48790 non-null  int64 \n",
      "dtypes: int64(13), object(9)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "adultDataFrame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3294677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Outliers(Imputation using Predictive modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe7048cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute Missing values for workclass\n",
    "\n",
    "\n",
    "#impute numerical columns with median \n",
    "num_imputer = SimpleImputer(strategy='median') \n",
    "adultDataFrame[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] = num_imputer.fit_transform(adultDataFrame[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']])\n",
    "\n",
    "#Separate rows with missing 'workclass' values\n",
    "missing_wc = adultDataFrame[adultDataFrame['workclass'].isna()] \n",
    "not_missing_wc = adultDataFrame[adultDataFrame['workclass'].notna()]\n",
    "\n",
    "#Label encode 'workclass' for rows without missing values\n",
    "le_wc = LabelEncoder()\n",
    "not_missing_wc['wc_Enc'] = le_wc.fit_transform(not_missing_wc['workclass'])\n",
    "\n",
    "#Features (excluding 'workplace') and target ('wc_Enc')\n",
    "X_wc = not_missing_wc[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "y_wc = not_missing_wc['wc_Enc']   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14eb37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier_wc = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# #perform cross validation \n",
    "# cross_val_score(svm_classifier_wc, X = X_wc, y = y_wc, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3f364b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validation Mean Accuracy: 71.27%\n",
      "XGBoost Cross-Validation Mean Accuracy: 74.90%\n",
      "Neural Network Cross-Validation Mean Accuracy: 71.21%\n",
      "Logistic Regression Cross-Validation Mean Accuracy: 73.56%\n"
     ]
    }
   ],
   "source": [
    "#comparing the accuarcy for different models and choosing the best model based on accuracy\n",
    "\n",
    "# List to store results\n",
    "model_scores = {}\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier_wc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf_classifier_wc, X=X_wc, y=y_wc, cv=5)\n",
    "model_scores['Random Forest'] = rf_cv_scores.mean()\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_classifier_wc = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_cv_scores = cross_val_score(xgb_classifier_wc, X=X_wc, y=y_wc, cv=5)\n",
    "model_scores['XGBoost'] = xgb_cv_scores.mean()\n",
    "\n",
    "# Neural Network (MLP Classifier)\n",
    "nn_classifier_wc = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "nn_cv_scores = cross_val_score(nn_classifier_wc, X=X_wc, y=y_wc, cv=5)\n",
    "model_scores['Neural Network'] = nn_cv_scores.mean()\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "logreg_classifier_wc = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_cv_scores = cross_val_score(logreg_classifier_wc, X=X_wc, y=y_wc, cv=5)\n",
    "model_scores['Logistic Regression'] = logreg_cv_scores.mean()\n",
    "\n",
    "# Print cross-validation results for all models\n",
    "for model_name, score in model_scores.items():\n",
    "    print(f\"{model_name} Cross-Validation Mean Accuracy: {score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c0447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the cross validation results XGBoost classifier has high accuracy but this model seems to \n",
    "#overfit the data by populating more blanks with never-worked class so we decided to go with next best model\n",
    "#that is logistic regression classifier\n",
    "\n",
    "#train logistic regression classifier for workclass\n",
    "rf_classifier_wc = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "#perform cross validation \n",
    "cross_val_score(rf_classifier_wc, X = X_wc, y = y_wc, cv = 5)\n",
    "\n",
    "#fit the model\n",
    "rf_classifier_wc.fit(X_wc, y_wc) \n",
    "\n",
    "\n",
    "#Predict missing 'workclass' for rows with missing values\n",
    "X_missing_wc = missing_wc[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "missing_wc_pred = rf_classifier_wc.predict(X_missing_wc[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']]) \n",
    "\n",
    "#Decode predicted 'workclass' back to original categories \n",
    "missing_wc['wc_Predicted'] = le_wc.inverse_transform(missing_wc_pred)\n",
    "\n",
    "#Fill missing 'workclass' with predicted values \n",
    "adultDataFrame.loc[adultDataFrame['workclass'].isna(), 'workclass'] = missing_wc['wc_Predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15846289",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workclass\n",
       "Private             36655\n",
       "Self-emp-not-inc     3861\n",
       "Local-gov            3136\n",
       "State-gov            1981\n",
       "Self-emp-inc         1694\n",
       "Federal-gov          1432\n",
       "Without-pay            21\n",
       "Never-worked           10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d767ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original dataset workclass \n",
    "# Private             33906\n",
    "# Self-emp-not-inc     3862\n",
    "# Local-gov            3136\n",
    "# State-gov            1981\n",
    "# ?                    1836\n",
    "# Self-emp-inc         1695\n",
    "# Federal-gov          1432\n",
    "# Without-pay            21\n",
    "# Never-worked           10\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "#random forest results\n",
    "#workclass\n",
    "# Private             35562\n",
    "# Self-emp-not-inc     3949\n",
    "# Local-gov            3198\n",
    "# State-gov            1992\n",
    "# Self-emp-inc         1706\n",
    "# Federal-gov          1440\n",
    "# Never-worked          921\n",
    "# Without-pay            22\n",
    "# Name: count, dtype: int64\n",
    "\n",
    "#logistic regression results\n",
    "# workclass\n",
    "# Private             36655\n",
    "# Self-emp-not-inc     3861\n",
    "# Local-gov            3136\n",
    "# State-gov            1981\n",
    "# Self-emp-inc         1694\n",
    "# Federal-gov          1432\n",
    "# Without-pay            21\n",
    "# Never-worked           10\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fd894676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute Missing values for occupation\n",
    "\n",
    "\n",
    "#impute numerical columns with median \n",
    "num_imputer = SimpleImputer(strategy='median') \n",
    "adultDataFrame[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] = num_imputer.fit_transform(adultDataFrame[['occupation_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']])\n",
    "\n",
    "#Separate rows with missing 'workclass' values\n",
    "missing_oc = adultDataFrame[adultDataFrame['occupation'].isna()] \n",
    "not_missing_oc = adultDataFrame[adultDataFrame['occupation'].notna()]\n",
    "\n",
    "#Label encode 'workclass' for rows without missing values\n",
    "le_oc = LabelEncoder()\n",
    "not_missing_oc['oc_Enc'] = le_oc.fit_transform(not_missing_oc['occupation'])\n",
    "\n",
    "#Features (excluding 'workplace') and target ('wc_Enc')\n",
    "X_oc = not_missing_oc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "y_oc = not_missing_oc['oc_Enc']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "29c34245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross-Validation Mean Accuracy: 99.31%\n",
      "XGBoost Cross-Validation Mean Accuracy: 100.00%\n",
      "Neural Network Cross-Validation Mean Accuracy: 92.79%\n",
      "Logistic Regression Cross-Validation Mean Accuracy: 36.22%\n"
     ]
    }
   ],
   "source": [
    "#comparing the accuarcy for different models and choosing the best model based on accuracy\n",
    "\n",
    "# List to store results\n",
    "model_scores = {}\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier_oc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf_classifier_oc, X=X_oc, y=y_oc, cv=5)\n",
    "model_scores['Random Forest'] = rf_cv_scores.mean()\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_classifier_oc = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_cv_scores = cross_val_score(xgb_classifier_oc, X=X_oc, y=y_oc, cv=5)\n",
    "model_scores['XGBoost'] = xgb_cv_scores.mean()\n",
    "\n",
    "# Neural Network (MLP Classifier)\n",
    "nn_classifier_oc = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "nn_cv_scores = cross_val_score(nn_classifier_oc, X=X_oc, y=y_oc, cv=5)\n",
    "model_scores['Neural Network'] = nn_cv_scores.mean()\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "logreg_classifier_oc = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_cv_scores = cross_val_score(logreg_classifier_oc, X=X_oc, y=y_oc, cv=5)\n",
    "model_scores['Logistic Regression'] = logreg_cv_scores.mean()\n",
    "\n",
    "# Print cross-validation results for all models\n",
    "for model_name, score in model_scores.items():\n",
    "    print(f\"{model_name} Cross-Validation Mean Accuracy: {score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ca5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest Cross-Validation Mean Accuracy: 99.31%\n",
    "XGBoost Cross-Validation Mean Accuracy: 100.00%\n",
    "Neural Network Cross-Validation Mean Accuracy: 92.79%\n",
    "Logistic Regression Cross-Validation Mean Accuracy: 36.22%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fdf53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the cross validation results XGBoost classifier has high accuracy but this model seems to \n",
    "#overfit the data by populating more blanks with never-worked class so we decided to go with next best model\n",
    "#that is logistic regression classifier\n",
    "\n",
    "#train logistic regression classifier for workclass\n",
    "xgb_classifier_oc = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "#perform cross validation \n",
    "cross_val_score(xgb_classifier_oc, X = X_oc, y = y_oc, cv = 5)\n",
    "\n",
    "#fit the model\n",
    "xgb_classifier_oc.fit(X_oc, y_oc) \n",
    "\n",
    "#Predict missing 'workclass' for rows with missing values\n",
    "X_missing_oc = missing_oc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "missing_oc_pred = xgb_classifier_oc.predict(X_missing_oc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']]) \n",
    "\n",
    "#Decode predicted 'workclass' back to original categories \n",
    "missing_oc['wc_Predicted'] = le_oc.inverse_transform(missing_oc_pred)\n",
    "\n",
    "#Fill missing 'workclass' with predicted values \n",
    "adultDataFrame.loc[adultDataFrame['occupation'].isna(), 'occupation'] = missing_oc['wc_Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79d30404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2805)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['occupation'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950ccc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe01bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399421d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be88e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1edb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569728e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ae931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a5683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f08eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198eb5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1b3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec8bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4712ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616eae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7638f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56342838-ca1f-4247-90b8-05857b936629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns with median \n",
    "num_imputer = SimpleImputer(strategy='median') \n",
    "adultDataFrame[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] = num_imputer.fit_transform(adultDataFrame[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']])\n",
    "\n",
    "#  ### Part 1: Impute Missing occupation ###\n",
    "\n",
    "# # Separate rows with missing 'occupation' \n",
    "missing_wc = adultDataFrame[adultDataFrame['occupation'].isna()] \n",
    "not_missing_wc = adultDataFrame[adultDataFrame['occupation'].notna()]\n",
    "\n",
    "# # Label encode 'workclass' for rows without missing values\n",
    "le_wc = LabelEncoder()\n",
    "not_missing_wc['oc_Enc'] = le_wc.fit_transform(not_missing_wc['occupation'])\n",
    "\n",
    "# # Features (excluding 'workplace') and target ('wc_Enc')\n",
    "X_wc = not_missing_wc[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "y_wc = not_missing_wc['oc_Enc']   \n",
    "\n",
    "\n",
    "# Train Random Forest Classifier for 'workclass' \n",
    "rf_classifier_wc = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "rf_classifier_wc.fit(X_wc[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']], y_wc) \n",
    "\n",
    "# # Predict missing 'workclass' for rows with missing values\n",
    "X_missing_wc = missing_wc[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "missing_wc_pred = rf_classifier_wc.predict(X_missing_wc[['education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']]) \n",
    "\n",
    "# Decode predicted 'workclass' back to original categories \n",
    "missing_wc['oc_Predicted'] = le_wc.inverse_transform(missing_wc_pred)\n",
    "\n",
    "# # Fill missing 'workclass' with predicted values \n",
    "adultDataFrame.loc[adultDataFrame['occupation'].isna(), 'occupation'] = missing_wc['oc_Predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d8896a5-66c2-45e5-8a0e-e7e9f3a7812a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "Prof-specialty       6462\n",
       "Craft-repair         6425\n",
       "Exec-managerial      6301\n",
       "Adm-clerical         6099\n",
       "Sales                5902\n",
       "Other-service        5539\n",
       "Machine-op-inspct    3125\n",
       "Transport-moving     2442\n",
       "Handlers-cleaners    2206\n",
       "Farming-fishing      1580\n",
       "Tech-support         1472\n",
       "Protective-serv      1009\n",
       "Priv-house-serv       264\n",
       "Armed-Forces           16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3e8d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Impute numerical columns with median \n",
    "# num_imputer = SimpleImputer(strategy='median') \n",
    "# adultDataFrame1[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] = num_imputer.fit_transform(adultDataFrame1[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']])\n",
    "\n",
    "# #  ### Part 1: Impute Missing occupation ###\n",
    "\n",
    "# # # Separate rows with missing 'occupation' \n",
    "# missing_wc = adultDataFrame1[adultDataFrame1['occupation'].isna()] \n",
    "# not_missing_wc = adultDataFrame1[adultDataFrame1['occupation'].notna()]\n",
    "\n",
    "# # # Label encode 'workclass' for rows without missing values\n",
    "# le_wc = LabelEncoder()\n",
    "# not_missing_wc['oc_Enc'] = le_wc.fit_transform(not_missing_wc['occupation'])\n",
    "\n",
    "# # # Features (excluding 'workplace') and target ('wc_Enc')\n",
    "# X_wc = not_missing_wc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "# y_wc = not_missing_wc['oc_Enc']   \n",
    "\n",
    "\n",
    "# # Train Random Forest Classifier for 'workclass' \n",
    "# rf_classifier_wc = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "# rf_classifier_wc.fit(X_wc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']], y_wc) \n",
    "\n",
    "# # # Predict missing 'workclass' for rows with missing values\n",
    "# X_missing_wc = missing_wc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "# missing_wc_pred = rf_classifier_wc.predict(X_missing_wc[['workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']]) \n",
    "\n",
    "# # Decode predicted 'workclass' back to original categories \n",
    "# missing_wc['oc_Predicted'] = le_wc.inverse_transform(missing_wc_pred)\n",
    "\n",
    "# # # Fill missing 'workclass' with predicted values \n",
    "# adultDataFrame1.loc[adultDataFrame1['occupation'].isna(), 'occupation'] = missing_wc['oc_Predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "632790cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "Prof-specialty       6706\n",
       "Exec-managerial      6345\n",
       "Adm-clerical         6294\n",
       "Craft-repair         6259\n",
       "Sales                5535\n",
       "Other-service        5499\n",
       "Machine-op-inspct    3027\n",
       "Transport-moving     2495\n",
       "Handlers-cleaners    2132\n",
       "Farming-fishing      1701\n",
       "Tech-support         1493\n",
       "Protective-serv      1099\n",
       "Priv-house-serv       242\n",
       "Armed-Forces           15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame1['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original dataset\n",
    "occupation\n",
    "Prof-specialty       6167\n",
    "Craft-repair         6107\n",
    "Exec-managerial      6084\n",
    "Adm-clerical         5608\n",
    "Sales                5504\n",
    "Other-service        4919\n",
    "Machine-op-inspct    3019\n",
    "Transport-moving     2355\n",
    "Handlers-cleaners    2071\n",
    "Farming-fishing      1487\n",
    "Tech-support         1445\n",
    "Protective-serv       983\n",
    "Priv-house-serv       240\n",
    "Armed-Forces           15\n",
    "\n",
    "#sailaja's initial \n",
    "occupation\n",
    "Craft-repair         6431\n",
    "Prof-specialty       6428\n",
    "Exec-managerial      6281\n",
    "Adm-clerical         6105\n",
    "Sales                5906\n",
    "Other-service        5523\n",
    "Machine-op-inspct    3130\n",
    "Transport-moving     2450\n",
    "Handlers-cleaners    2228\n",
    "Farming-fishing      1587\n",
    "Tech-support         1467\n",
    "Protective-serv      1006\n",
    "Priv-house-serv       256\n",
    "Armed-Forces           15\n",
    "\n",
    "#sailaja's latest\n",
    "Prof-specialty       6436\n",
    "Craft-repair         6429\n",
    "Exec-managerial      6289\n",
    "Adm-clerical         6087\n",
    "Sales                5906\n",
    "Other-service        5524\n",
    "Machine-op-inspct    3140\n",
    "Transport-moving     2443\n",
    "Handlers-cleaners    2218\n",
    "Farming-fishing      1582\n",
    "Tech-support         1473\n",
    "Protective-serv      1013\n",
    "Priv-house-serv       258\n",
    "Armed-Forces           15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64fee00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income_enc\n",
       "0    37155\n",
       "1    11687\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame1['income_enc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8eb96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns with median \n",
    "num_imputer = SimpleImputer(strategy='median') \n",
    "adultDataFrame1[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] = num_imputer.fit_transform(adultDataFrame1[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']])\n",
    "\n",
    "#  ### Part 1: Impute Missing native-country ###\n",
    "\n",
    "# # Separate rows with missing 'occupation' \n",
    "missing_wc = adultDataFrame1[adultDataFrame1['native-country'].isna()] \n",
    "not_missing_wc = adultDataFrame1[adultDataFrame1['native-country'].notna()]\n",
    "\n",
    "# # Label encode 'workclass' for rows without missing values\n",
    "le_wc = LabelEncoder()\n",
    "not_missing_wc['nc_Enc'] = le_wc.fit_transform(not_missing_wc['native-country'])\n",
    "\n",
    "# # Features (excluding 'workplace') and target ('wc_Enc')\n",
    "X_wc = not_missing_wc[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "y_wc = not_missing_wc['nc_Enc']   \n",
    "\n",
    "\n",
    "# Train Random Forest Classifier for 'workclass' \n",
    "rf_classifier_wc = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "rf_classifier_wc.fit(X_wc[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']], y_wc) \n",
    "\n",
    "# # Predict missing 'workclass' for rows with missing values\n",
    "X_missing_wc = missing_wc[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']] \n",
    "missing_wc_pred = rf_classifier_wc.predict(X_missing_wc[['occupation_enc','workclass_enc','education_new_enc','sex_enc','marital-status_enc','age','relationship_enc','race_enc','hours-per-week','capital-gain','capital-loss','income_enc']]) \n",
    "\n",
    "# Decode predicted 'workclass' back to original categories \n",
    "missing_wc['nc_Predicted'] = le_wc.inverse_transform(missing_wc_pred)\n",
    "\n",
    "# # Fill missing 'workclass' with predicted values \n",
    "adultDataFrame1.loc[adultDataFrame1['native-country'].isna(), 'native-country'] = missing_wc['nc_Predicted']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a64bc2-a91c-459a-8c05-f7b74ca46595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52fc6bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "native-country\n",
       "United-States                 44596\n",
       "Mexico                          967\n",
       "Philippines                     321\n",
       "Germany                         206\n",
       "Puerto-Rico                     185\n",
       "Canada                          182\n",
       "India                           161\n",
       "El-Salvador                     156\n",
       "Cuba                            138\n",
       "China                           137\n",
       "England                         127\n",
       "South                           121\n",
       "Jamaica                         106\n",
       "Italy                           105\n",
       "Dominican-Republic              103\n",
       "Japan                            96\n",
       "Vietnam                          89\n",
       "Guatemala                        88\n",
       "Poland                           87\n",
       "Columbia                         85\n",
       "Haiti                            75\n",
       "Taiwan                           67\n",
       "Portugal                         67\n",
       "Iran                             61\n",
       "Nicaragua                        49\n",
       "Greece                           49\n",
       "Peru                             46\n",
       "Ecuador                          45\n",
       "France                           38\n",
       "Ireland                          37\n",
       "Hong                             33\n",
       "Thailand                         30\n",
       "Trinadad&Tobago                  28\n",
       "Cambodia                         28\n",
       "Laos                             24\n",
       "Outlying-US(Guam-USVI-etc)       24\n",
       "Yugoslavia                       24\n",
       "Scotland                         21\n",
       "Honduras                         20\n",
       "Hungary                          19\n",
       "Holand-Netherlands                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataFrame1['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1a852-d139-49b3-b665-80068bc2616a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c35248-f468-4b0d-9d5e-66eda954af3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa47185-30e2-4e26-9933-0b2d4b54c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection by using random forest classifier\n",
    "# Label Encoding for categorical columns\n",
    "# Create a list of categorical columns\n",
    "categorical_cols = adult_df_featsel.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to all categorical columns\n",
    "for col in categorical_cols:\n",
    "    adult_df_featsel[col] = label_encoder.fit_transform(adult_df_featsel[col])\n",
    "    \n",
    "# Split the data\n",
    "X = adult_df_featsel.drop(columns='income')\n",
    "y = adult_df_featsel['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "#Feature Importance using Random Forest\n",
    "feature_importances = rf_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feat_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "feat_importance_df = feat_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feat_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1e159-3fd4-4f01-8fbd-c1d545d91524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d927d8-aca1-4b3e-ba51-efafeba8ab24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8acd256-9e4e-4ad6-ad37-5c2ccb61b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filling the missing values for workclass column\n",
    "\n",
    "# #identify missing values in workclass column\n",
    "# test_data = adultDataFrame1[(adultDataFrame1['workclass'].isnull())].copy()\n",
    "# test_label = test_data.workclass\n",
    "\n",
    "# train_data = adultDataFrame1[(adultDataFrame1['workclass'].notnull())].copy()\n",
    "# train_label = train_data.workclass\n",
    "\n",
    "# #remove the workclass column from train data and test data\n",
    "# test_data.drop(columns = ['workclass'], inplace = True)\n",
    "# train_data.drop(columns = ['workclass'], inplace = True)\n",
    "\n",
    "# # Initialize OneHotEncoder\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# # Fit the encoder on the training data\n",
    "# train_encoded = encoder.fit_transform(train_data)\n",
    "\n",
    "# # Apply the same encoding to the test data\n",
    "# test_encoded = encoder.transform(test_data)\n",
    "\n",
    "# # Ensure both datasets have the same columns\n",
    "# train_data_encoded = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out())\n",
    "# test_data_encoded = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "\n",
    "# # Perform one-hot encoding on train_data and test_data\n",
    "# train_data_encoded = pd.get_dummies(train_data)\n",
    "# test_data_encoded = pd.get_dummies(test_data)\n",
    "\n",
    "# # Ensure test_data_encoded has the same columns as train_data_encoded\n",
    "# test_data_encoded = test_data_encoded.reindex(columns=train_data_encoded.columns, fill_value=0)\n",
    "\n",
    "# #Train and predict the model using logistic regression\n",
    "# log_reg = LogisticRegression()\n",
    "# log_reg.fit(train_data_encoded, train_label)\n",
    "# log_reg_pred = log_reg.predict(test_data_encoded)\n",
    "\n",
    "# #Train and predict the model using decision tree classifier\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(train_data_encoded, train_label)\n",
    "# clf_pred = clf.predict(test_data_encoded)\n",
    "\n",
    "# #Train and predict the model using random forest classifier\n",
    "# r_forest = RandomForestClassifier(n_estimators=10)\n",
    "# r_forest.fit(train_data_encoded, train_label)\n",
    "# r_forest_pred = r_forest.predict(test_data_encoded)\n",
    "\n",
    "# # Determine the majority class for 'workclass'\n",
    "# majority_class = adultDataFrame1.workclass.value_counts().index[0]\n",
    "\n",
    "# # Create DataFrame for predictions from different models\n",
    "# pred_df = pd.DataFrame({'RFor': r_forest_pred, 'DTree': clf_pred, 'LogReg': log_reg_pred})\n",
    "# #pred_df\n",
    "\n",
    "# #Determine the overall prediction using majority voting\n",
    "# overall_pred = pred_df.apply(lambda x: x.value_counts().index[0] if x.value_counts()[0] > 1 else majority_class, axis=1)\n",
    "# #overall_pred\n",
    "\n",
    "# # Ensure the 'overall_pred' has the same index as the rows we want to update\n",
    "# mask = adultDataFrame1['workclass'].isnull()\n",
    "# adultDataFrame1.loc[mask, 'workclass'] = overall_pred.values\n",
    "\n",
    "# # Verify the results\n",
    "# print(adultDataFrame1.workclass.value_counts())\n",
    "# print(adultDataFrame1.workclass.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf86da1e-d3bc-46be-8f39-7e2ab9991cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'State-gov'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 3. Exploratory Data Analysis (EDA)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Correlation analysis (only for numeric features)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43madultDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10704\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10702\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10703\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10704\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10707\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'State-gov'"
     ]
    }
   ],
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "# Correlation analysis (only for numeric features)\n",
    "sns.heatmap(adultDataFrame.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9113ba-7275-4cdb-983c-755b7080cf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac55e8e-a2a2-4cef-9bb7-9da7672248d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to use\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate confusion matrix and accuracy\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[model_name] = {\n",
    "        'Confusion Matrix': cm,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    # Print the results for each model\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{cm}\\n\")\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "# Optional: Print all results at once\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6836d91-93bf-442c-be4d-4c552a369852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Preprocessing\n",
    "# Label Encoding for categorical variables\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "\n",
    "# Normalization/Standardization\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']] = scaler.fit_transform(\n",
    "    df[['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']]\n",
    ")\n",
    "\n",
    "# Splitting features and target\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0022c8-004a-48c7-a05d-69ee27814f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature Selection (using Chi-square test for categorical-target relationships)\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4440dd1-9cd1-4d1d-8bd1-4c8553337cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Training Setup\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524582a-5cc3-43c4-9ff3-199e4a66a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model Explanation and Execution (RandomForestClassifier with hyperparameter tuning)\n",
    "pipeline = Pipeline([\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e26ca-fef1-4461-87c5-efea57f959ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Evaluation\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Best parameters found by grid search\n",
    "print(\"\\nBest Hyperparameters:\\n\", grid_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
